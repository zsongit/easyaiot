#!/bin/bash

# ============================================
# EasyAIoT 中间件部署脚本
# ============================================
# 使用方法：
#   ./install_all.sh [命令]
#
# 可用命令：
#   install    - 安装并启动所有中间件（首次运行）
#   start      - 启动所有中间件
#   stop       - 停止所有中间件
#   restart    - 重启所有中间件
#   status     - 查看所有中间件状态
#   logs       - 查看中间件日志
#   build      - 重新构建所有镜像
#   clean      - 清理所有容器和镜像
#   update     - 更新并重启所有中间件
# ============================================

set -e

# 颜色定义
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# 脚本所在目录
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$SCRIPT_DIR"

COMPOSE_FILE="${SCRIPT_DIR}/docker-compose.yml"

# 日志文件配置
LOG_DIR="${SCRIPT_DIR}/logs"
mkdir -p "$LOG_DIR"
chmod -R 777 "$LOG_DIR" 2>/dev/null || sudo chmod -R 777 "$LOG_DIR" 2>/dev/null || true
LOG_FILE="${LOG_DIR}/install_middleware_$(date +%Y%m%d_%H%M%S).log"

# 初始化日志文件
echo "=========================================" >> "$LOG_FILE"
echo "EasyAIoT 中间件部署脚本日志" >> "$LOG_FILE"
echo "开始时间: $(date '+%Y-%m-%d %H:%M:%S')" >> "$LOG_FILE"
echo "命令: $*" >> "$LOG_FILE"
echo "=========================================" >> "$LOG_FILE"
echo "" >> "$LOG_FILE"

# 中间件服务列表
MIDDLEWARE_SERVICES=(
    "Nacos"
    "PostgresSQL"
    "TDengine"
    "Redis"
    "Kafka"
    "MinIO"
    "SRS"
    "NodeRED"
    "EMQX"
)

# 中间件端口映射
declare -A MIDDLEWARE_PORTS
MIDDLEWARE_PORTS["Nacos"]="8848"
MIDDLEWARE_PORTS["PostgresSQL"]="5432"
MIDDLEWARE_PORTS["TDengine"]="6030"
MIDDLEWARE_PORTS["Redis"]="6379"
MIDDLEWARE_PORTS["Kafka"]="9092"
MIDDLEWARE_PORTS["MinIO"]="9000"
MIDDLEWARE_PORTS["SRS"]="1935"
MIDDLEWARE_PORTS["NodeRED"]="1880"
MIDDLEWARE_PORTS["EMQX"]="1883"

# 中间件健康检查端点
declare -A MIDDLEWARE_HEALTH_ENDPOINTS
MIDDLEWARE_HEALTH_ENDPOINTS["Nacos"]="/nacos/actuator/health"
MIDDLEWARE_HEALTH_ENDPOINTS["PostgresSQL"]=""
MIDDLEWARE_HEALTH_ENDPOINTS["TDengine"]=""
MIDDLEWARE_HEALTH_ENDPOINTS["Redis"]=""
MIDDLEWARE_HEALTH_ENDPOINTS["Kafka"]=""
MIDDLEWARE_HEALTH_ENDPOINTS["MinIO"]="/minio/health/live"
MIDDLEWARE_HEALTH_ENDPOINTS["SRS"]="/api/v1/versions"
MIDDLEWARE_HEALTH_ENDPOINTS["NodeRED"]="/"
MIDDLEWARE_HEALTH_ENDPOINTS["EMQX"]="/api/v5/status"

# 日志输出函数（去掉颜色代码后写入日志文件）
log_to_file() {
    local message="$1"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    # 去掉 ANSI 颜色代码
    local clean_message=$(echo "$message" | sed -r "s/\x1B\[([0-9]{1,2}(;[0-9]{1,2})?)?[mGK]//g")
    echo "[$timestamp] $clean_message" >> "$LOG_FILE"
}

# 打印带颜色的消息（同时输出到日志文件）
print_info() {
    local message="${BLUE}[INFO]${NC} $1"
    echo -e "$message"
    log_to_file "[INFO] $1"
}

print_success() {
    local message="${GREEN}[SUCCESS]${NC} $1"
    echo -e "$message"
    log_to_file "[SUCCESS] $1"
}

print_warning() {
    local message="${YELLOW}[WARNING]${NC} $1"
    echo -e "$message"
    log_to_file "[WARNING] $1"
}

print_error() {
    local message="${RED}[ERROR]${NC} $1"
    echo -e "$message"
    log_to_file "[ERROR] $1"
}

print_section() {
    local section="$1"
    echo ""
    echo -e "${YELLOW}========================================${NC}"
    echo -e "${YELLOW}  $section${NC}"
    echo -e "${YELLOW}========================================${NC}"
    echo ""
    log_to_file ""
    log_to_file "========================================="
    log_to_file "  $section"
    log_to_file "========================================="
    log_to_file ""
}

# 检查命令是否存在
check_command() {
    if ! command -v "$1" &> /dev/null; then
        return 1
    fi
    return 0
}

# 检查 Git 是否已安装
check_git() {
    if check_command git; then
        local git_version=$(git --version 2>&1)
        print_success "Git 已安装: $git_version"
        return 0
    fi
    return 1
}

# 检查并提示安装 Git
check_and_require_git() {
    if check_git; then
        return 0
    fi
    
    print_error "未检测到 Git"
    echo ""
    print_info "Git 是运行此项目的必需组件"
    echo ""
    
    # 检测系统类型
    local os_id=""
    if [ -f /etc/os-release ]; then
        . /etc/os-release
        os_id="$ID"
    fi
    
    # 根据系统类型提供安装指导
    echo ""
    print_warning "请按照以下步骤安装 Git："
    echo ""
    
    case "$os_id" in
        ubuntu|debian)
            print_info "Debian/Ubuntu 系统安装命令："
            print_info "  sudo apt update"
            print_info "  sudo apt install -y git"
            ;;
        centos|rhel|fedora)
            print_info "CentOS/RHEL/Fedora 系统安装命令："
            print_info "  sudo yum install -y git"
            ;;
        *)
            print_info "请访问 Git 官网获取安装指南："
            print_info "  https://git-scm.com/download/linux"
            ;;
    esac
    
    echo ""
    print_error "Git 是必需的，安装流程已终止"
    print_info "安装 Git 后，请重新运行此脚本"
    exit 1
}


# 检查 nvidia-container-toolkit 是否已安装
check_nvidia_container_toolkit() {
    if command -v nvidia-container-runtime &> /dev/null; then
        local runtime_path=$(which nvidia-container-runtime)
        print_success "nvidia-container-toolkit 已安装: $runtime_path"
        return 0
    fi
    
    # 检查是否通过包管理器安装
    if dpkg -l | grep -q nvidia-container-toolkit 2>/dev/null || rpm -qa | grep -q nvidia-container-toolkit 2>/dev/null; then
        print_info "nvidia-container-toolkit 已通过包管理器安装"
        return 0
    fi
    
    return 1
}

# 安装 nvidia-container-toolkit
install_nvidia_container_toolkit() {
    print_section "安装 NVIDIA Container Toolkit"
    
    if [ "$EUID" -ne 0 ]; then
        print_warning "安装 nvidia-container-toolkit 需要 root 权限，跳过自动安装"
        print_info "如果后续需要使用 GPU，请手动安装 nvidia-container-toolkit"
        print_info "安装指南: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html"
        return 1
    fi
    
    # 检测系统类型
    if [ -f /etc/os-release ]; then
        . /etc/os-release
        local os_id="$ID"
    else
        print_error "无法检测操作系统类型"
        return 1
    fi
    
    # 第一步：卸载旧版本（如果存在）
    print_info "检查并卸载旧版本..."
    case "$os_id" in
        ubuntu|debian)
            apt-get purge -y nvidia-docker2 nvidia-container-toolkit 2>/dev/null || true
            rm -rf /etc/nvidia-container-runtime 2>/dev/null || true
            ;;
        centos|rhel|fedora)
            yum remove -y nvidia-docker2 nvidia-container-toolkit 2>/dev/null || true
            rm -rf /etc/nvidia-container-runtime 2>/dev/null || true
            ;;
        *)
            print_warning "不支持的操作系统: $os_id，尝试通用卸载方法"
            rm -rf /etc/nvidia-container-runtime 2>/dev/null || true
            ;;
    esac
    
    # 第二步：添加 NVIDIA 仓库并安装
    print_info "添加 NVIDIA 仓库..."
    case "$os_id" in
        ubuntu|debian)
            # 添加密钥和仓库（添加重试机制）
            local gpg_key_added=0
            local max_retries=3
            local retry_count=0
            
            while [ $retry_count -lt $max_retries ] && [ $gpg_key_added -eq 0 ]; do
                if curl -fsSL --connect-timeout 10 --max-time 30 https://nvidia.github.io/libnvidia-container/gpgkey | gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg 2>/dev/null; then
                    gpg_key_added=1
                    print_success "NVIDIA GPG 密钥添加成功"
                else
                    retry_count=$((retry_count + 1))
                    if [ $retry_count -lt $max_retries ]; then
                        print_warning "添加 NVIDIA GPG 密钥失败，正在重试 ($retry_count/$max_retries)..."
                        sleep 2
                    else
                        print_error "添加 NVIDIA GPG 密钥失败（已重试 $max_retries 次）"
                        print_warning "可能是网络问题，将尝试使用备用方法或跳过此步骤"
                        
                        # 尝试使用备用方法：直接下载密钥文件
                        print_info "尝试使用备用方法添加 GPG 密钥..."
                        if curl -fsSL --connect-timeout 10 --max-time 30 "https://nvidia.github.io/libnvidia-container/gpgkey" -o /tmp/nvidia-gpgkey 2>/dev/null && \
                           gpg --dearmor /tmp/nvidia-gpgkey -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg 2>/dev/null; then
                            rm -f /tmp/nvidia-gpgkey
                            gpg_key_added=1
                            print_success "使用备用方法成功添加 NVIDIA GPG 密钥"
                        else
                            rm -f /tmp/nvidia-gpgkey
                            print_error "备用方法也失败，nvidia-container-toolkit 安装将跳过"
                            print_info "如果后续需要使用 GPU，请手动安装 nvidia-container-toolkit"
                            print_info "安装指南: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html"
                            return 1
                        fi
                    fi
                fi
            done
            
            # 如果 GPG 密钥添加失败，直接返回
            if [ $gpg_key_added -eq 0 ]; then
                return 1
            fi
            
            # 添加仓库列表（添加重试机制）
            local repo_added=0
            local max_retries=3
            local retry_count=0
            
            while [ $retry_count -lt $max_retries ] && [ $repo_added -eq 0 ]; do
                if curl -fsSL --connect-timeout 10 --max-time 30 https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
                   sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
                   tee /etc/apt/sources.list.d/nvidia-container-toolkit.list > /dev/null; then
                    repo_added=1
                    print_success "NVIDIA 仓库添加成功"
                else
                    retry_count=$((retry_count + 1))
                    if [ $retry_count -lt $max_retries ]; then
                        print_warning "添加 NVIDIA 仓库失败，正在重试 ($retry_count/$max_retries)..."
                        sleep 2
                    else
                        print_error "添加 NVIDIA 仓库失败（已重试 $max_retries 次）"
                        return 1
                    fi
                fi
            done
            
            # 更新包列表
            if ! apt-get update -qq > /dev/null 2>&1; then
                print_error "更新包列表失败"
                return 1
            fi
            
            # 安装 nvidia-container-toolkit
            print_info "正在安装 nvidia-container-toolkit..."
            if ! apt-get install -qq -y nvidia-container-toolkit > /dev/null 2>&1; then
                print_error "安装 nvidia-container-toolkit 失败"
                return 1
            fi
            ;;
        centos|rhel|fedora)
            # 添加仓库
            if ! curl -fsSL https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo | \
                tee /etc/yum.repos.d/nvidia-container-toolkit.repo > /dev/null; then
                print_error "添加 NVIDIA 仓库失败"
                return 1
            fi
            
            # 安装 nvidia-container-toolkit
            print_info "正在安装 nvidia-container-toolkit..."
            if ! yum install -y nvidia-container-toolkit; then
                print_error "安装 nvidia-container-toolkit 失败"
                return 1
            fi
            ;;
        *)
            print_error "不支持的操作系统: $os_id"
            print_info "请手动安装 nvidia-container-toolkit 后重试"
            print_info "安装指南: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html"
            return 1
            ;;
    esac
    
    # 第三步：配置 Docker 使用 NVIDIA 作为默认运行时
    print_info "配置 Docker 使用 NVIDIA 作为默认运行时..."
    if ! nvidia-ctk runtime configure --runtime=docker; then
        print_error "配置 Docker runtime 失败"
        return 1
    fi
    
    # 第四步：重启 Docker
    print_info "重启 Docker 服务以使配置生效..."
    systemctl daemon-reload
    if ! systemctl restart docker; then
        print_error "重启 Docker 服务失败"
        return 1
    fi
    
    # 第五步：验证安装
    print_info "验证安装..."
    sleep 2  # 等待服务启动
    
    if command -v nvidia-container-runtime &> /dev/null; then
        local runtime_path=$(which nvidia-container-runtime)
        print_success "nvidia-container-runtime 已安装: $runtime_path"
    else
        print_warning "nvidia-container-runtime 未在 PATH 中找到，但包已安装"
    fi
    
    # 测试运行 GPU 容器（可选，如果系统有 GPU）
    if command -v nvidia-smi &> /dev/null; then
        print_info "检测到 NVIDIA GPU，测试 GPU 容器..."
        if docker run --rm --gpus all nvidia/cuda:11.8.0-base nvidia-smi &> /dev/null; then
            print_success "GPU 容器测试成功"
        else
            print_warning "GPU 容器测试失败，但 nvidia-container-toolkit 已安装"
            print_info "请检查 NVIDIA 驱动是否正确安装"
        fi
    else
        print_info "未检测到 NVIDIA GPU，跳过 GPU 容器测试"
    fi
    
    print_success "NVIDIA Container Toolkit 安装完成"
    return 0
}

# 检查并安装 nvidia-container-toolkit
check_and_install_nvidia_container_toolkit() {
    if check_nvidia_container_toolkit; then
        return 0
    fi
    
    print_warning "未检测到 nvidia-container-toolkit"
    echo ""
    print_info "nvidia-container-toolkit 是 Docker 容器使用 GPU 的必需组件"
    print_info "如果没有 NVIDIA GPU 或不需要 GPU 支持，可以跳过此步骤"
    echo ""
    
    while true; do
        echo -ne "${YELLOW}[提示]${NC} 是否自动安装 nvidia-container-toolkit？(y/N): "
        read -r response
        case "$response" in
            [yY][eE][sS]|[yY])
                if [ "$EUID" -ne 0 ]; then
                    print_warning "安装 nvidia-container-toolkit 需要 root 权限，跳过自动安装"
                    print_info "如果后续需要使用 GPU，请手动安装 nvidia-container-toolkit"
                    print_info "安装指南: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html"
                    return 0
                fi
                if install_nvidia_container_toolkit; then
                    print_success "nvidia-container-toolkit 安装成功"
                    return 0
                else
                    print_warning "nvidia-container-toolkit 安装失败"
                    print_info "这可能是由于网络问题导致的，不影响其他服务的安装"
                    print_info "如果后续需要使用 GPU，请手动安装 nvidia-container-toolkit"
                    print_info "安装指南: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html"
                    echo ""
                    print_warning "是否继续安装其他服务？(y/N): "
                    read -r continue_response
                    case "$continue_response" in
                        [yY][eE][sS]|[yY])
                            print_info "继续安装其他服务..."
                            return 0
                            ;;
                        *)
                            print_info "已取消安装"
                            exit 1
                            ;;
                    esac
                fi
                ;;
            [nN][oO]|[nN]|"")
                print_info "跳过 nvidia-container-toolkit 安装"
                print_info "如果后续需要使用 GPU，请手动安装 nvidia-container-toolkit"
                return 0
                ;;
            *)
                print_warning "请输入 y 或 N"
                ;;
        esac
    done
}

# 检测系统是否有 NVIDIA GPU 支持
check_nvidia_gpu_support() {
    # 方法1: 检查 nvidia-smi 命令
    if command -v nvidia-smi &> /dev/null; then
        if nvidia-smi &> /dev/null; then
            return 0  # 有 GPU 支持
        fi
    fi
    
    # 方法2: 检查 /dev/nvidia* 设备文件
    if ls /dev/nvidia* &> /dev/null; then
        return 0  # 有 GPU 支持
    fi
    
    # 方法3: 检查 nvidia-container-toolkit 是否已安装且可用
    if check_nvidia_container_toolkit; then
        # 如果已安装，尝试测试 GPU 容器
        if docker run --rm --gpus all nvidia/cuda:11.8.0-base nvidia-smi &> /dev/null 2>&1; then
            return 0  # 有 GPU 支持
        fi
    fi
    
    return 1  # 没有 GPU 支持
}

# 配置 Docker 镜像源
configure_docker_mirror() {
    print_section "配置 Docker 镜像源和 NVIDIA Runtime"
    
    local docker_config_dir="/etc/docker"
    local docker_config_file="$docker_config_dir/daemon.json"
    
    if [ "$EUID" -ne 0 ]; then
        print_warning "配置 Docker 镜像源需要 root 权限，跳过此步骤"
        return 0
    fi
    
    # 检测是否有 GPU 支持
    local has_gpu=0
    if check_nvidia_gpu_support; then
        has_gpu=1
        print_info "检测到 NVIDIA GPU 支持，将配置 NVIDIA runtime"
    else
        print_info "未检测到 NVIDIA GPU 支持，将跳过 default-runtime 配置"
        print_info "如果后续需要 GPU 支持，请安装 nvidia-container-toolkit 后重新运行此脚本"
    fi
    
    # 创建 docker 配置目录
    mkdir -p "$docker_config_dir"
    
    # 使用 Python 精确检查和配置
    print_info "正在检查并配置 Docker 配置..."
    
    local output_file=$(mktemp)
    local python_exit_code=0
    
    python3 << EOF > "$output_file" 2>&1
import json
import sys
import os

config_file = "$docker_config_file"
has_gpu = $has_gpu
# 推荐的镜像源列表（只保留 docker.1ms.run）
recommended_mirrors = [
    "https://docker.1ms.run/"
]
nvidia_runtime = {
    "path": "nvidia-container-runtime",
    "runtimeArgs": []
}
# 只有在有 GPU 支持时才设置 default-runtime
required_default_runtime = "nvidia" if has_gpu else None

# 读取现有配置
config = {}
if os.path.exists(config_file):
    try:
        with open(config_file, 'r') as f:
            config = json.load(f)
    except Exception as e:
        print(f"CONFIG_ERROR:读取配置文件失败: {e}", file=sys.stderr)
        sys.exit(1)

needs_update = False
changes = []

# 检查并添加镜像源（保留用户已有的，只添加缺失的）
if "registry-mirrors" not in config:
    config["registry-mirrors"] = []
    needs_update = True
    changes.append("添加 registry-mirrors 配置")

# 获取现有镜像源列表
existing_mirrors = config.get("registry-mirrors", [])
# 确保是列表类型
if not isinstance(existing_mirrors, list):
    existing_mirrors = []

# 添加缺失的推荐镜像源（保留用户已有的配置）
added_mirrors = []
for mirror in recommended_mirrors:
    # 检查镜像源是否已存在（支持带/和不带/的匹配）
    mirror_normalized = mirror.rstrip('/')
    exists = False
    for existing in existing_mirrors:
        existing_normalized = existing.rstrip('/')
        if mirror_normalized == existing_normalized:
            exists = True
            break
    
    if not exists:
        existing_mirrors.append(mirror)
        added_mirrors.append(mirror)
        needs_update = True

if added_mirrors:
    config["registry-mirrors"] = existing_mirrors
    changes.append(f"添加镜像源: {', '.join(added_mirrors)}")

# 检查并添加 NVIDIA runtime
# 注意：即使没有 GPU，也保留 runtime 配置（如果 nvidia-container-toolkit 已安装）
# 这样后续安装 GPU 后可以直接使用，不需要重新配置
if "runtimes" not in config:
    config["runtimes"] = {}
    needs_update = True
    changes.append("添加 runtimes 配置")

# 检查 nvidia-container-toolkit 是否已安装
nvidia_toolkit_installed = False
try:
    import subprocess
    result = subprocess.run(["which", "nvidia-container-runtime"], 
                          capture_output=True, timeout=2)
    nvidia_toolkit_installed = (result.returncode == 0)
except:
    pass

# 只有在 nvidia-container-toolkit 已安装或检测到 GPU 时才配置 runtime
# 这样可以避免在没有工具包的情况下配置无效的 runtime
if nvidia_toolkit_installed or has_gpu:
    if "nvidia" not in config["runtimes"]:
        config["runtimes"]["nvidia"] = nvidia_runtime
        needs_update = True
        changes.append("添加 NVIDIA runtime 配置")
    else:
        # 检查现有配置是否正确
        nvidia_config = config["runtimes"]["nvidia"]
        if nvidia_config.get("path") != nvidia_runtime["path"]:
            config["runtimes"]["nvidia"] = nvidia_runtime
            needs_update = True
            changes.append("更新 NVIDIA runtime 配置")

# 检查并添加 default-runtime（只有在有 GPU 支持时才设置）
if required_default_runtime is not None:
    # 有 GPU 支持，需要设置 default-runtime
    if "default-runtime" not in config:
        config["default-runtime"] = required_default_runtime
        needs_update = True
        changes.append(f"添加 default-runtime: {required_default_runtime}")
    elif config["default-runtime"] != required_default_runtime:
        config["default-runtime"] = required_default_runtime
        needs_update = True
        changes.append(f"更新 default-runtime: {required_default_runtime}")
else:
    # 没有 GPU 支持，如果现有配置是 nvidia，需要移除或改为默认
    if "default-runtime" in config and config["default-runtime"] == "nvidia":
        # 移除 default-runtime 配置，让 Docker 使用默认运行时
        del config["default-runtime"]
        needs_update = True
        changes.append("移除 default-runtime 配置（系统无 GPU 支持）")

# 写入配置文件
if needs_update:
    try:
        with open(config_file, 'w') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        print("CONFIG_UPDATED")
        for change in changes:
            print(f"CHANGE:{change}")
    except Exception as e:
        print(f"CONFIG_ERROR:{e}", file=sys.stderr)
        sys.exit(1)
else:
    print("CONFIG_OK")
EOF
    
    python_exit_code=$?
    local config_updated=false
    local config_ok=false
    
    # 解析 Python 输出
    while IFS= read -r line || [ -n "$line" ]; do
        if [[ $line == CONFIG_UPDATED ]]; then
            config_updated=true
        elif [[ $line == CONFIG_OK ]]; then
            config_ok=true
        elif [[ $line == CHANGE:* ]]; then
            local change="${line#CHANGE:}"
            print_info "配置变更: $change"
        elif [[ $line == CONFIG_ERROR:* ]]; then
            local error="${line#CONFIG_ERROR:}"
            print_error "配置失败: $error"
            rm -f "$output_file"
            return 1
        fi
    done < "$output_file"
    
    rm -f "$output_file"
    
    if [ $python_exit_code -ne 0 ]; then
        print_error "Docker 配置检查失败"
        return 1
    fi
    
    if [ "$config_ok" = true ]; then
        print_success "Docker 配置已完整（镜像源、NVIDIA runtime、default-runtime 均已配置）"
    elif [ "$config_updated" = true ]; then
        print_success "Docker 配置已更新"
        
        # 重启 Docker 服务使配置生效
        if systemctl is-active --quiet docker; then
            print_info "正在重启 Docker 服务以使配置生效..."
            systemctl daemon-reload
            systemctl restart docker
            print_success "Docker 服务已重启"
        fi
    else
        print_warning "Docker 配置检查完成，但未发现需要更新的配置"
    fi
}

# 配置 pip 镜像源
configure_pip_mirror() {
    print_section "配置 pip 镜像源"
    
    local pip_config_dir="$HOME/.pip"
    local pip_config_file="$pip_config_dir/pip.conf"
    
    # 创建 pip 配置目录
    mkdir -p "$pip_config_dir"
    
    # 检查是否已配置
    if [ -f "$pip_config_file" ]; then
        if grep -q "index-url" "$pip_config_file"; then
            print_info "pip 镜像源已配置，跳过"
            return 0
        fi
    fi
    
    print_info "正在配置 pip 镜像源..."
    
    # 创建或更新配置文件
    cat > "$pip_config_file" << EOF
[global]
index-url = https://mirrors.huaweicloud.com/repository/pypi/simple
trusted-host = mirrors.huaweicloud.com

[install]
trusted-host = mirrors.huaweicloud.com
EOF
    
    print_success "pip 镜像源配置完成"
    print_info "已使用华为云镜像源: https://mirrors.huaweicloud.com/repository/pypi/simple"
}

# 配置 apt 国内源
configure_apt_mirror() {
    print_section "配置 apt 国内源"
    
    # 检测系统类型
    if [ ! -f /etc/os-release ]; then
        print_warning "无法检测操作系统类型，跳过 apt 源配置"
        return 0
    fi
    
    . /etc/os-release
    local os_id="$ID"
    
    # 只处理 Debian/Ubuntu 系统
    if [ "$os_id" != "ubuntu" ] && [ "$os_id" != "debian" ]; then
        print_info "当前系统不是 Debian/Ubuntu，跳过 apt 源配置"
        return 0
    fi
    
    # 检查是否有 root 权限
    if [ "$EUID" -ne 0 ]; then
        print_warning "配置 apt 源需要 root 权限，跳过此步骤"
        print_info "如需配置 apt 源，请使用 sudo 运行此脚本"
        return 0
    fi
    
    # 检查用户是否已经选择过（通过标记文件）
    local apt_mirror_marker="/etc/apt/.easyaiot_mirror_configured"
    
    # 先检查当前系统是否已配置国内 apt 源（完整检查，包括 sources.list 和 sources.list.d）
    local current_sources_list="/etc/apt/sources.list"
    local current_sources_content=""
    local is_current_domestic=false
    
    # 读取当前系统的 apt 源配置
    if [ -f "$current_sources_list" ]; then
        current_sources_content=$(cat "$current_sources_list")
        # 检查是否已经是国内源（包含常见国内镜像关键词）
        # 匹配模式：tuna、aliyun、163、ustc、huawei、tencent 等国内镜像站
        if echo "$current_sources_content" | grep -qiE "(mirrors\.(tuna|aliyun|163|ustc|huawei|tencent)|tuna\.tsinghua|aliyun\.com|163\.com|ustc\.edu|huawei\.com|tencent\.com|mirror\.nju\.edu\.cn|mirrors\.bfsu\.edu\.cn)"; then
            is_current_domestic=true
        fi
    fi
    
    # 如果主配置文件不是国内源，检查 sources.list.d 目录下的文件
    if [ "$is_current_domestic" = false ] && [ -d "/etc/apt/sources.list.d" ]; then
        for list_file in /etc/apt/sources.list.d/*.list; do
            if [ -f "$list_file" ]; then
                local file_content=$(cat "$list_file")
                if echo "$file_content" | grep -qiE "(mirrors\.(tuna|aliyun|163|ustc|huawei|tencent)|tuna\.tsinghua|aliyun\.com|163\.com|ustc\.edu|huawei\.com|tencent\.com|mirror\.nju\.edu\.cn|mirrors\.bfsu\.edu\.cn)"; then
                    is_current_domestic=true
                    break
                fi
            fi
        done
    fi
    
    # 如果当前系统已经配置了国内源，直接跳过，不提示用户，并记录标记
    if [ "$is_current_domestic" = true ]; then
        print_info "检测到系统已配置国内 apt 源，跳过配置步骤"
        echo "configured" > "$apt_mirror_marker" 2>/dev/null || true
        return 0
    fi
    
    # 如果系统未配置国内源，检查标记文件
    if [ -f "$apt_mirror_marker" ]; then
        local user_choice=$(cat "$apt_mirror_marker" 2>/dev/null || echo "")
        if [ "$user_choice" = "skip" ]; then
            print_info "检测到用户已选择跳过 apt 源配置，跳过此步骤"
            return 0
        elif [ "$user_choice" = "configured" ]; then
            # 标记文件显示已配置，但实际检查未发现国内源，说明配置可能被删除了
            # 清除标记文件，让用户重新选择
            print_warning "检测到标记文件显示已配置，但实际未发现国内源配置，清除标记文件"
            rm -f "$apt_mirror_marker"
        fi
    fi
    
    # 读取本地 apt 源配置（用于替换）
    local local_sources_list="/etc/apt/sources.list"
    local local_sources_content=""
    local has_local_source=false
    local is_domestic_mirror=false
    
    if [ -f "$local_sources_list" ]; then
        local_sources_content=$(cat "$local_sources_list")
        has_local_source=true
        # 检查是否是国内源（包含常见国内镜像关键词）
        if echo "$local_sources_content" | grep -qiE "(mirrors\.(tuna|aliyun|163|ustc|huawei|tencent)|tuna\.tsinghua|aliyun\.com|163\.com|ustc\.edu|huawei\.com|tencent\.com)"; then
            is_domestic_mirror=true
        fi
    fi
    
    # 询问用户是否替换 apt 源
    echo ""
    print_warning "为了加快软件包下载速度，建议使用国内 apt 源"
    if [ "$has_local_source" = true ]; then
        if [ "$is_domestic_mirror" = true ]; then
            print_info "检测到本地已配置国内 apt 源，可以使用本地配置替换当前系统 apt 源"
        else
            print_info "检测到本地 apt 源配置，将使用本地配置替换当前系统 apt 源"
        fi
    else
        print_info "当前系统 apt 源可能下载较慢，建议替换为国内镜像源"
    fi
    echo ""
    
    while true; do
        echo -ne "${YELLOW}[提示]${NC} 是否替换 apt 源为国内源？(y/N): "
        read -r response
        case "$response" in
            [yY][eE][sS]|[yY])
                # 用户选择替换
                print_info "正在配置 apt 国内源..."
                
                # 备份现有的 sources.list
                local sources_list="/etc/apt/sources.list"
                local backup_file="${sources_list}.bak.$(date +%Y%m%d_%H%M%S)"
                
                if [ -f "$sources_list" ]; then
                    cp "$sources_list" "$backup_file"
                    print_success "已备份现有 apt 源配置到: $backup_file"
                fi
                
                # 如果本地有 apt 源配置，使用本地配置
                if [ "$has_local_source" = true ] && [ -n "$local_sources_content" ]; then
                    print_info "使用本地 apt 源配置..."
                    echo "$local_sources_content" > "$sources_list"
                    print_success "已使用本地 apt 源配置替换系统 apt 源"
                else
                    # 否则使用默认的国内源配置
                    print_info "使用默认国内 apt 源配置..."
                    
                    # 检测系统版本
                    local codename=""
                    if [ -n "$VERSION_CODENAME" ]; then
                        codename="$VERSION_CODENAME"
                    elif [ -n "$UBUNTU_CODENAME" ]; then
                        codename="$UBUNTU_CODENAME"
                    else
                        # 尝试从 lsb_release 获取
                        if command -v lsb_release &> /dev/null; then
                            codename=$(lsb_release -cs 2>/dev/null || echo "")
                        fi
                    fi
                    
                    if [ -z "$codename" ]; then
                        print_error "无法检测系统版本代号，跳过 apt 源配置"
                        return 1
                    fi
                    
                    print_info "检测到系统版本代号: $codename"
                    
                    # 根据系统类型配置国内源
                    if [ "$os_id" = "ubuntu" ]; then
                        # Ubuntu 使用清华大学镜像源
                        cat > "$sources_list" << EOF
# 清华大学 Ubuntu 镜像源
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ $codename main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ $codename-updates main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ $codename-backports main restricted universe multiverse
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ $codename-security main restricted universe multiverse

# 源码仓库（可选）
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ $codename main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ $codename-updates main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ $codename-backports main restricted universe multiverse
# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ $codename-security main restricted universe multiverse
EOF
                        print_success "已配置 Ubuntu 清华大学镜像源"
                    elif [ "$os_id" = "debian" ]; then
                        # Debian 使用清华大学镜像源
                        local debian_version=""
                        if [ -n "$VERSION_ID" ]; then
                            debian_version=$(echo "$VERSION_ID" | cut -d. -f1)
                        fi
                        
                        if [ -z "$debian_version" ]; then
                            # 尝试从 codename 推断版本
                            case "$codename" in
                                bookworm)
                                    debian_version="12"
                                    ;;
                                bullseye)
                                    debian_version="11"
                                    ;;
                                buster)
                                    debian_version="10"
                                    ;;
                                *)
                                    debian_version="12"
                                    print_warning "无法确定 Debian 版本，使用默认版本 12"
                                    ;;
                            esac
                        fi
                        
                        cat > "$sources_list" << EOF
# 清华大学 Debian 镜像源
deb https://mirrors.tuna.tsinghua.edu.cn/debian/ $codename main contrib non-free non-free-firmware
deb https://mirrors.tuna.tsinghua.edu.cn/debian/ $codename-updates main contrib non-free non-free-firmware
deb https://mirrors.tuna.tsinghua.edu.cn/debian/ $codename-backports main contrib non-free non-free-firmware
deb https://mirrors.tuna.tsinghua.edu.cn/debian-security $codename-security main contrib non-free non-free-firmware

# 源码仓库（可选）
# deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ $codename main contrib non-free non-free-firmware
# deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ $codename-updates main contrib non-free non-free-firmware
# deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ $codename-backports main contrib non-free non-free-firmware
# deb-src https://mirrors.tuna.tsinghua.edu.cn/debian-security $codename-security main contrib non-free non-free-firmware
EOF
                        print_success "已配置 Debian 清华大学镜像源"
                    fi
                fi
                
                # 更新 apt 缓存
                print_info "正在更新 apt 缓存..."
                if apt update -qq > /dev/null 2>&1; then
                    print_success "apt 源配置完成并已更新缓存"
                    # 记录已配置标记
                    echo "configured" > "$apt_mirror_marker" 2>/dev/null || true
                else
                    print_warning "apt 源配置完成，但更新缓存时出现问题"
                    print_info "您可以稍后手动运行: apt update"
                    # 即使更新失败，也记录已配置标记（因为源文件已修改）
                    echo "configured" > "$apt_mirror_marker" 2>/dev/null || true
                fi
                
                return 0
                ;;
            [nN][oO]|[nN]|"")
                # 用户选择不替换，继续执行，并记录标记
                print_info "保持当前 apt 源配置，继续执行..."
                echo "skip" > "$apt_mirror_marker" 2>/dev/null || true
                return 0
                ;;
            *)
                print_warning "请输入 y 或 N"
                ;;
        esac
    done
}


# 检查 Docker Compose 版本是否符合要求（>=2.35.0）
check_docker_compose_version() {
    local compose_version_output=""
    local version_string=""
    
    # 检查 docker-compose 独立版本
    if check_command docker-compose; then
        compose_version_output=$(docker-compose --version 2>&1)
        version_string=$(echo "$compose_version_output" | grep -oE '[0-9]+\.[0-9]+\.[0-9]+' | head -n 1)
    # 检查 docker compose plugin 版本
    elif docker compose version &> /dev/null; then
        compose_version_output=$(docker compose version 2>&1)
        version_string=$(echo "$compose_version_output" | grep -oE '[0-9]+\.[0-9]+\.[0-9]+' | head -n 1)
    else
        return 1
    fi
    
    if [ -z "$version_string" ]; then
        print_warning "无法解析 Docker Compose 版本: $compose_version_output"
        return 1
    fi
    
    # 比较版本号
    local major=$(echo "$version_string" | cut -d. -f1)
    local minor=$(echo "$version_string" | cut -d. -f2)
    local patch=$(echo "$version_string" | cut -d. -f3)
    
    # 要求版本 >= 2.35.0
    if [ "$major" -gt 2 ] || ([ "$major" -eq 2 ] && [ "$minor" -gt 35 ]) || ([ "$major" -eq 2 ] && [ "$minor" -eq 35 ] && [ "$patch" -ge 0 ]); then
        print_success "Docker Compose 版本符合要求: $version_string"
        return 0
    else
        print_warning "Docker Compose 版本过低: $version_string，需要 v2.35.0+"
        return 1
    fi
}

# 检查 Docker 权限
check_docker_permission() {
    # 先检查 Docker 是否安装
    if ! check_command docker; then
        print_error "Docker 未安装"
        return 1
    fi
    
    # 检查是否有权限访问 Docker daemon
    if ! docker ps &> /dev/null; then
        print_error "没有权限访问 Docker daemon"
        echo ""
        echo "解决方案："
        echo "  1. 将当前用户添加到 docker 组："
        echo "     sudo usermod -aG docker $USER"
        echo "     然后重新登录或运行: newgrp docker"
        echo ""
        echo "  2. 或者使用 sudo 运行此脚本："
        echo "     sudo ./install_middleware.sh $*"
        echo ""
        exit 1
    fi
}

# 安装 Docker
install_docker() {
    print_section "安装 Docker"
    
    if [ "$EUID" -ne 0 ]; then
        print_warning "安装 Docker 需要 root 权限，跳过自动安装"
        print_info "请手动安装 Docker 后继续，或使用 sudo 运行此脚本"
        print_info "安装指南: https://docs.docker.com/get-docker/"
        return 1
    fi
    
    # 询问用户 Docker data-root 路径
    echo ""
    print_warning "Docker 默认会将数据存储在系统盘（/var/lib/docker），如果系统盘空间较小，建议指定其他路径"
    echo ""
    print_info "请输入 Docker 数据存储路径（data-root）："
    print_info "  直接回车将使用默认路径: /var/lib/docker"
    print_info "  建议使用大容量磁盘路径，例如: /data/docker 或 /mnt/docker"
    echo ""
    
    local docker_data_root=""
    while true; do
        echo -ne "${YELLOW}[提示]${NC} 请输入 Docker data-root 路径（直接回车使用默认路径）: "
        read -r docker_data_root
        
        # 如果用户直接回车，使用默认路径
        if [ -z "$docker_data_root" ]; then
            docker_data_root="/var/lib/docker"
            print_info "使用默认路径: $docker_data_root"
            break
        fi
        
        # 验证路径格式（必须是绝对路径）
        if [[ ! "$docker_data_root" =~ ^/ ]]; then
            print_error "请输入绝对路径（以 / 开头）"
            continue
        fi
        
        # 检查路径是否已存在且可写
        if [ -d "$docker_data_root" ]; then
            if [ ! -w "$docker_data_root" ]; then
                print_error "路径 $docker_data_root 不可写，请选择其他路径"
                continue
            fi
        else
            # 尝试创建目录
            if ! mkdir -p "$docker_data_root" 2>/dev/null; then
                print_error "无法创建路径 $docker_data_root，请检查权限或选择其他路径"
                continue
            fi
        fi
        
        print_success "将使用路径: $docker_data_root"
        break
    done
    
    # 检测系统类型
    if [ -f /etc/os-release ]; then
        . /etc/os-release
        local os_id="$ID"
    else
        print_error "无法检测操作系统类型"
        return 1
    fi
    
    # 根据系统类型安装 Docker（使用华为云镜像源）
    case "$os_id" in
        ubuntu|debian)
            print_info "检测到 Debian/Ubuntu 系统，开始安装 Docker（使用华为云镜像源）..."
            
            # 卸载旧版本
            apt-get remove -y docker docker-engine docker.io containerd runc 2>/dev/null || true
            
            # 安装依赖
            apt-get update -qq > /dev/null 2>&1
            apt-get install -qq -y \
                ca-certificates \
                curl \
                gnupg \
                lsb-release > /dev/null 2>&1
            
            # 添加 Docker 官方 GPG 密钥（使用华为云镜像加速）
            install -m 0755 -d /etc/apt/keyrings
            # 尝试使用华为云镜像加速下载 GPG 密钥，如果失败则使用官方源
            if ! curl -fsSL --connect-timeout 10 --max-time 30 https://mirrors.huaweicloud.com/docker-ce/linux/$os_id/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg 2>/dev/null; then
                print_warning "华为云镜像下载 GPG 密钥失败，使用官方源..."
                curl -fsSL https://download.docker.com/linux/$os_id/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg
            fi
            chmod a+r /etc/apt/keyrings/docker.gpg
            
            # 设置仓库（使用华为云镜像源）
            echo \
              "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://mirrors.huaweicloud.com/docker-ce/linux/$os_id \
              $(lsb_release -cs) stable" | tee /etc/apt/sources.list.d/docker.list > /dev/null
            
            # 安装 Docker Engine（包含 docker-compose-plugin）
            apt-get update -qq > /dev/null 2>&1
            apt-get install -qq -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin > /dev/null 2>&1
            
            print_success "Docker 和 Docker Compose 已通过华为云镜像源安装完成"
            
            ;;
        centos|rhel|fedora)
            print_info "检测到 CentOS/RHEL/Fedora 系统，开始安装 Docker（使用华为云镜像源）..."
            
            # 卸载旧版本
            yum remove -y docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-engine 2>/dev/null || true
            
            # 安装依赖
            yum install -y yum-utils
            
            # 添加 Docker 仓库（使用华为云镜像源）
            if ! yum-config-manager --add-repo https://mirrors.huaweicloud.com/docker-ce/linux/centos/docker-ce.repo 2>/dev/null; then
                print_warning "华为云镜像添加仓库失败，使用官方源..."
                yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
            fi
            
            # 安装 Docker Engine（包含 docker-compose-plugin）
            yum install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
            
            print_success "Docker 和 Docker Compose 已通过华为云镜像源安装完成"
            
            ;;
        *)
            print_error "不支持的操作系统: $os_id"
            print_info "请手动安装 Docker 后重试"
            print_info "安装指南: https://docs.docker.com/get-docker/"
            return 1
            ;;
    esac
    
    # 配置 Docker data-root（在启动服务之前）
    if [ "$docker_data_root" != "/var/lib/docker" ]; then
        print_info "配置 Docker data-root 为: $docker_data_root"
        
        local docker_config_dir="/etc/docker"
        local docker_config_file="$docker_config_dir/daemon.json"
        
        mkdir -p "$docker_config_dir"
        
        # 读取或创建配置文件
        local config_content="{}"
        if [ -f "$docker_config_file" ]; then
            config_content=$(cat "$docker_config_file")
        fi
        
        # 使用 Python 更新配置
        python3 << EOF
import json
import sys

config_file = "$docker_config_file"
data_root = "$docker_data_root"

try:
    config = json.loads('''$config_content''')
except:
    config = {}

config["data-root"] = data_root

try:
    with open(config_file, 'w') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    print("CONFIG_UPDATED")
except Exception as e:
    print(f"CONFIG_ERROR:{e}", file=sys.stderr)
    sys.exit(1)
EOF
        
        if [ $? -ne 0 ]; then
            print_error "配置 Docker data-root 失败"
            return 1
        fi
        
        print_success "Docker data-root 已配置为: $docker_data_root"
        print_warning "注意：如果 /var/lib/docker 已有数据，需要手动迁移到新路径"
    fi
    
    # 启动 Docker 服务
    print_info "启动 Docker 服务..."
    systemctl daemon-reload
    systemctl enable docker
    systemctl start docker
    
    # 验证安装
    if check_command docker; then
        print_success "Docker 安装完成: $(docker --version)"
        return 0
    else
        print_error "Docker 安装验证失败"
        return 1
    fi
}

# 安装 Docker Compose（直接使用包管理器，不再从 GitHub 下载）
install_docker_compose() {
    print_section "安装 Docker Compose"
    
    if [ "$EUID" -ne 0 ]; then
        print_warning "安装 Docker Compose 需要 root 权限，跳过自动安装"
        print_info "请手动安装 Docker Compose 后继续，或使用 sudo 运行此脚本"
        print_info "Docker Compose 会随 Docker 一起安装（docker-compose-plugin）"
        return 1
    fi
    
    # 检测系统类型
    if [ -f /etc/os-release ]; then
        . /etc/os-release
        local os_id="$ID"
    else
        print_error "无法检测操作系统类型"
        return 1
    fi
    
    # 根据系统类型安装 Docker Compose Plugin（使用华为云镜像源）
    case "$os_id" in
        ubuntu|debian)
            print_info "检测到 Debian/Ubuntu 系统，安装 Docker Compose Plugin（使用华为云镜像源）..."
            apt-get update -qq > /dev/null 2>&1
            apt-get install -qq -y docker-compose-plugin > /dev/null 2>&1
            ;;
        centos|rhel|fedora)
            print_info "检测到 CentOS/RHEL/Fedora 系统，安装 Docker Compose Plugin（使用华为云镜像源）..."
            yum install -y docker-compose-plugin
            ;;
        *)
            print_error "不支持的操作系统: $os_id"
            return 1
            ;;
    esac
    
    # 验证安装
    if check_command docker-compose || docker compose version &> /dev/null; then
        if check_command docker-compose; then
            print_success "Docker Compose 安装完成: $(docker-compose --version)"
        else
            print_success "Docker Compose Plugin 安装完成: $(docker compose version)"
        fi
        return 0
    else
        print_error "Docker Compose 安装验证失败"
        return 1
    fi
}

# 检查并安装 Docker
check_and_install_docker() {
    if check_command docker; then
        if check_docker_permission "$@"; then
            return 0
        else
            # Docker 未安装，继续安装流程
            print_warning "Docker 未安装"
        fi
    else
        print_warning "未检测到 Docker"
    fi
    
    echo ""
    print_info "Docker 是运行中间件服务的必需组件"
    echo ""
    
    while true; do
        echo -ne "${YELLOW}[提示]${NC} 是否自动安装 Docker？(y/N): "
        read -r response
        case "$response" in
            [yY][eE][sS]|[yY])
                if install_docker; then
                    print_success "Docker 安装成功"
                    # 安装后再次检查权限
                    if check_docker_permission "$@"; then
                        return 0
                    else
                        print_warning "Docker 安装成功但无法访问，请检查权限"
                        print_info "请确保当前用户在 docker 组中: sudo usermod -aG docker $USER"
                        return 1
                    fi
                else
                    print_warning "Docker 安装失败，请手动安装后重试"
                    print_info "安装指南: https://docs.docker.com/get-docker/"
                    return 1
                fi
                ;;
            [nN][oO]|[nN]|"")
                print_warning "Docker 是必需的，但安装流程将继续"
                print_info "请确保已安装 Docker，否则无法继续"
                print_info "安装指南: https://docs.docker.com/get-docker/"
                return 1
                ;;
            *)
                print_warning "请输入 y 或 N"
                ;;
        esac
    done
}

# 检查并安装 Docker Compose
check_and_install_docker_compose() {
    if check_command docker-compose || docker compose version &> /dev/null; then
        # 检查版本是否符合要求
        if check_docker_compose_version; then
            # 检查是 docker-compose 还是 docker compose
            if check_command docker-compose; then
                COMPOSE_CMD="docker-compose"
                print_success "Docker Compose 已安装: $(docker-compose --version)"
            else
                COMPOSE_CMD="docker compose"
                print_success "Docker Compose 已安装: $(docker compose version)"
            fi
            return 0
        else
            # 版本不符合要求，提示升级
            local current_version=""
            if check_command docker-compose; then
                current_version=$(docker-compose --version 2>&1)
            else
                current_version=$(docker compose version 2>&1)
            fi
            
            print_warning "Docker Compose 版本不符合要求（需要 v2.35.0+）"
            echo ""
            print_info "当前版本: $current_version"
            print_info "要求版本: v2.35.0 或更高"
            echo ""
            
            while true; do
                echo -ne "${YELLOW}[提示]${NC} 是否升级 Docker Compose？(y/N): "
                read -r response
                case "$response" in
                    [yY][eE][sS]|[yY])
                        if [ "$EUID" -ne 0 ]; then
                            print_warning "升级 Docker Compose 需要 root 权限，跳过自动升级"
                            print_info "请手动升级 Docker Compose 后继续，或使用 sudo 运行此脚本"
                            print_info "升级命令: sudo apt-get update && sudo apt-get install --upgrade docker-compose-plugin"
                            return 1
                        fi
                        print_info "正在升级 Docker Compose（使用包管理器）..."
                        # 检测系统类型
                        if [ -f /etc/os-release ]; then
                            . /etc/os-release
                            local os_id="$ID"
                        else
                            print_error "无法检测操作系统类型"
                            return 1
                        fi
                        
                        # 使用包管理器升级
                        case "$os_id" in
                            ubuntu|debian)
                                apt-get update -qq > /dev/null 2>&1
                                apt-get install --upgrade -qq -y docker-compose-plugin > /dev/null 2>&1
                                ;;
                            centos|rhel|fedora)
                                yum update -y docker-compose-plugin
                                ;;
                            *)
                                print_error "不支持的操作系统: $os_id"
                                return 1
                                ;;
                        esac
                        
                        if check_docker_compose_version; then
                            # 重新检查并设置 COMPOSE_CMD
                            if check_command docker-compose; then
                                COMPOSE_CMD="docker-compose"
                            else
                                COMPOSE_CMD="docker compose"
                            fi
                            print_success "Docker Compose 升级成功"
                            return 0
                        else
                            print_warning "Docker Compose 升级后版本仍不符合要求"
                            return 1
                        fi
                        ;;
                    [nN][oO]|[nN]|"")
                        print_warning "Docker Compose 版本不符合要求，但安装流程将继续"
                        print_info "请手动升级 Docker Compose 到 v2.35.0+"
                        print_info "升级命令: sudo apt-get update && sudo apt-get install --upgrade docker-compose-plugin"
                        return 1
                        ;;
                    *)
                        print_warning "请输入 y 或 N"
                        ;;
                esac
            done
        fi
    fi
    
    print_warning "未检测到 Docker Compose"
    echo ""
    print_info "Docker Compose 是运行中间件服务的必需组件"
    print_info "要求版本: v2.35.0 或更高"
    print_info "Docker Compose 会通过包管理器安装（docker-compose-plugin）"
    echo ""
    
    while true; do
        echo -ne "${YELLOW}[提示]${NC} 是否自动安装 Docker Compose？(y/N): "
        read -r response
        case "$response" in
            [yY][eE][sS]|[yY])
                if install_docker_compose; then
                    if check_docker_compose_version; then
                        print_success "Docker Compose 安装成功"
                        # 重新检查并设置 COMPOSE_CMD
                        if check_command docker-compose; then
                            COMPOSE_CMD="docker-compose"
                        else
                            COMPOSE_CMD="docker compose"
                        fi
                        return 0
                    else
                        print_warning "Docker Compose 安装后版本不符合要求"
                        return 1
                    fi
                else
                    print_warning "Docker Compose 安装失败，请手动安装后重试"
                    return 1
                fi
                ;;
            [nN][oO]|[nN]|"")
                print_warning "Docker Compose 是必需的，但安装流程将继续"
                print_info "请确保已安装 Docker Compose v2.35.0+"
                print_info "安装命令: sudo apt-get update && sudo apt-get install docker-compose-plugin"
                return 1
                ;;
            *)
                print_warning "请输入 y 或 N"
                ;;
        esac
    done
}

# 检查 Docker 是否安装（保持向后兼容）
check_docker() {
    check_and_install_docker "$@"
}

# 检查 Docker Compose 是否安装（保持向后兼容）
check_docker_compose() {
    check_and_install_docker_compose
}

# 创建统一网络
create_network() {
    print_info "创建统一网络 easyaiot-network..."
    
    # 检查网络是否已存在
    if docker network ls | grep -q easyaiot-network; then
        print_info "网络 easyaiot-network 已存在，跳过创建"
        # 简化处理：如果网络已存在，直接使用，不进行任何测试（避免卡住）
        # 如果网络真的有问题，后续启动容器时会报错，届时再处理
        return 0
    fi
    
    # 创建网络（如果不存在或已删除）
    print_info "正在创建网络 easyaiot-network..."
    local create_output=$(docker network create easyaiot-network 2>&1)
    local create_exit_code=$?
    
    if [ $create_exit_code -eq 0 ]; then
        print_success "网络 easyaiot-network 已创建"
        return 0
    else
        # 检查错误原因
        if echo "$create_output" | grep -qi "already exists"; then
            print_info "网络 easyaiot-network 已存在（可能在检查后创建）"
            return 0
        elif echo "$create_output" | grep -qi "permission denied"; then
            print_error "没有权限创建 Docker 网络"
            print_info "请确保当前用户在 docker 组中，或使用 sudo 运行脚本"
            return 1
        elif echo "$create_output" | grep -qi "network with name.*already exists"; then
            print_warning "网络名称冲突，尝试使用不同的方法..."
            # 再次检查网络是否存在
            if docker network ls | grep -q easyaiot-network; then
                print_info "网络已存在，继续使用现有网络"
                return 0
            else
                print_error "无法创建网络: $create_output"
                return 1
            fi
        else
            print_error "无法创建网络 easyaiot-network"
            print_error "错误信息: $create_output"
            print_info "诊断建议："
            print_info "  1. 检查 Docker 服务是否正常运行: sudo systemctl status docker"
            print_info "  2. 检查当前用户是否有权限: docker network ls"
            print_info "  3. 查看 Docker 日志: sudo journalctl -u docker.service"
            return 1
        fi
    fi
}

# 检查 IP 地址是否为 Docker 网络 IP
is_docker_network_ip() {
    local ip="$1"
    if [ -z "$ip" ]; then
        return 1
    fi
    
    # Docker 默认网段：172.17.0.0/16 到 172.31.0.0/16
    # 这些是 Docker 自动分配的桥接网络网段
    if [[ "$ip" =~ ^172\.(1[7-9]|2[0-9]|3[0-1])\.[0-9]+\.[0-9]+$ ]]; then
        return 0  # 是 Docker 网络 IP
    fi
    
    return 1  # 不是 Docker 网络 IP
}

# 检查网络接口是否为 Docker 相关接口
is_docker_interface() {
    local iface="$1"
    if [ -z "$iface" ]; then
        return 1
    fi
    
    # Docker 相关接口名称模式
    if [[ "$iface" =~ ^(docker|br-|veth|br[0-9]+) ]]; then
        return 0  # 是 Docker 接口
    fi
    
    return 1  # 不是 Docker 接口
}

# 获取宿主机 IP 地址（排除 Docker 网络接口）
get_host_ip() {
    local host_ip=""
    
    # 方法1: 通过路由获取（最可靠，通常返回物理网络接口的 IP）
    if command -v ip &> /dev/null; then
        host_ip=$(ip route get 8.8.8.8 2>/dev/null | awk '{print $7}' | head -n 1)
        if [ -n "$host_ip" ] && [ "$host_ip" != "127.0.0.1" ] && ! is_docker_network_ip "$host_ip"; then
            echo "$host_ip"
            return 0
        fi
    fi
    
    # 方法2: 通过 hostname -I 获取，过滤 Docker 网络 IP
    if command -v hostname &> /dev/null; then
        local all_ips=$(hostname -I 2>/dev/null)
        if [ -n "$all_ips" ]; then
            # 遍历所有 IP，找到第一个非 Docker 网络的 IP
            for ip in $all_ips; do
                if [ "$ip" != "127.0.0.1" ] && [[ ! "$ip" =~ ^169\.254\. ]] && ! is_docker_network_ip "$ip"; then
                    echo "$ip"
                    return 0
                fi
            done
        fi
    fi
    
    # 方法3: 通过 ip addr 获取，排除 Docker 接口和 Docker 网络 IP
    if command -v ip &> /dev/null; then
        # 获取所有网络接口的 IP，优先选择物理接口（eth*, enp*, ens*, eno*）
        local physical_ips=""
        local other_ips=""
        local current_iface=""
        
        while IFS= read -r line; do
            # 提取接口名称（格式：1: eth0: <...>）
            if [[ "$line" =~ ^[0-9]+:[[:space:]]+([^:]+): ]]; then
                current_iface="${BASH_REMATCH[1]}"
                # 跳过 Docker 接口
                if is_docker_interface "$current_iface"; then
                    current_iface=""
                    continue
                fi
            fi
            
            # 提取 IP 地址（格式：    inet 192.168.1.100/24 ...）
            if [ -n "$current_iface" ] && [[ "$line" =~ inet[[:space:]]+([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+) ]]; then
                local ip="${BASH_REMATCH[1]}"
                if [ "$ip" != "127.0.0.1" ] && [[ ! "$ip" =~ ^169\.254\. ]] && ! is_docker_network_ip "$ip"; then
                    # 检查是否是物理接口
                    if [[ "$current_iface" =~ ^(eth|enp|ens|eno|wlan|wlp) ]]; then
                        physical_ips="$physical_ips $ip"
                    else
                        other_ips="$other_ips $ip"
                    fi
                fi
            fi
        done < <(ip addr show 2>/dev/null)
        
        # 优先使用物理接口的 IP
        if [ -n "$physical_ips" ]; then
            host_ip=$(echo "$physical_ips" | awk '{print $1}')
            if [ -n "$host_ip" ]; then
                echo "$host_ip"
                return 0
            fi
        fi
        
        # 如果没有物理接口 IP，使用其他接口的 IP
        if [ -n "$other_ips" ]; then
            host_ip=$(echo "$other_ips" | awk '{print $1}')
            if [ -n "$host_ip" ]; then
                echo "$host_ip"
                return 0
            fi
        fi
    fi
    
    # 方法4: 通过 ifconfig 获取（兼容旧系统），排除 Docker 接口
    if command -v ifconfig &> /dev/null; then
        local current_iface=""
        while IFS= read -r line; do
            # 检测接口名称
            if [[ "$line" =~ ^([^[:space:]]+)[[:space:]]+ ]]; then
                current_iface="${BASH_REMATCH[1]}"
                # 跳过 Docker 接口
                if is_docker_interface "$current_iface"; then
                    current_iface=""
                    continue
                fi
            fi
            
            # 提取 IP 地址
            if [ -n "$current_iface" ] && [[ "$line" =~ inet[[:space:]]+([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+) ]]; then
                local ip="${BASH_REMATCH[1]}"
                if [ "$ip" != "127.0.0.1" ] && [[ ! "$ip" =~ ^169\.254\. ]] && ! is_docker_network_ip "$ip"; then
                    echo "$ip"
                    return 0
                fi
            fi
        done < <(ifconfig 2>/dev/null)
    fi
    
    # 如果所有方法都失败，返回空字符串
    echo ""
    return 1
}

# 创建并设置 NodeRED 数据目录权限
create_nodered_directories() {
    local nodered_data_dir="${SCRIPT_DIR}/nodered_data/data"
    
    print_info "创建 NodeRED 数据目录并设置权限..."
    
    # 创建目录
    mkdir -p "$nodered_data_dir"
    
    # 设置目录所有者为 UID 1000 (Node-RED 容器默认用户)
    # 如果当前用户有权限，则设置；否则只创建目录
    if [ "$EUID" -eq 0 ]; then
        chown -R 1000:1000 "$nodered_data_dir"
        chmod -R 777 "$nodered_data_dir"
        print_success "NodeRED 数据目录权限已设置 (UID 1000:1000, 777)"
    else
        # 非 root 用户尝试使用 sudo（如果可用）
        if command -v sudo &> /dev/null; then
            sudo chown -R 1000:1000 "$nodered_data_dir" 2>/dev/null && \
            sudo chmod -R 777 "$nodered_data_dir" 2>/dev/null && \
            print_success "NodeRED 数据目录权限已设置 (UID 1000:1000, 777)" || \
            print_warning "无法设置 NodeRED 目录权限，可能需要手动设置: sudo chmod -R 777 $nodered_data_dir"
        else
            print_warning "无法设置 NodeRED 目录权限，请手动执行: sudo chmod -R 777 $nodered_data_dir"
        fi
    fi
}

# 创建并设置 PostgreSQL 数据目录权限
create_postgresql_directories() {
    local postgresql_data_dir="${SCRIPT_DIR}/db_data/data"
    local postgresql_log_dir="${SCRIPT_DIR}/db_data/log"
    
    print_info "创建 PostgreSQL 数据目录并设置权限..."
    
    # 创建目录
    mkdir -p "$postgresql_data_dir" "$postgresql_log_dir"
    
    # 设置目录所有者为 UID 999 (PostgreSQL 容器默认 postgres 用户)
    # 如果当前用户有权限，则设置；否则只创建目录
    if [ "$EUID" -eq 0 ]; then
        chown -R 999:999 "$postgresql_data_dir" "$postgresql_log_dir"
        chmod -R 777 "$postgresql_data_dir"
        chmod -R 777 "$postgresql_log_dir"
        print_success "PostgreSQL 数据目录权限已设置 (UID 999:999, 777)"
    else
        # 非 root 用户尝试使用 sudo（如果可用）
        if command -v sudo &> /dev/null; then
            sudo chown -R 999:999 "$postgresql_data_dir" "$postgresql_log_dir" 2>/dev/null && \
            sudo chmod -R 777 "$postgresql_data_dir" 2>/dev/null && \
            sudo chmod -R 777 "$postgresql_log_dir" 2>/dev/null && \
            print_success "PostgreSQL 数据目录权限已设置 (UID 999:999, 777)" || \
            print_warning "无法设置 PostgreSQL 目录权限，可能需要手动设置: sudo chmod -R 777 $postgresql_data_dir $postgresql_log_dir"
        else
            print_warning "无法设置 PostgreSQL 目录权限，请手动执行: sudo chmod -R 777 $postgresql_data_dir $postgresql_log_dir"
        fi
    fi
}

# 创建并设置 Redis 数据目录权限
create_redis_directories() {
    local redis_data_dir="${SCRIPT_DIR}/redis_data/data"
    local redis_log_dir="${SCRIPT_DIR}/redis_data/logs"
    
    print_info "创建 Redis 数据目录并设置权限..."
    
    # 创建目录
    mkdir -p "$redis_data_dir" "$redis_log_dir"
    
    # Redis 容器默认使用 UID 999 (redis 用户)
    # 如果当前用户有权限，则设置；否则只创建目录
    if [ "$EUID" -eq 0 ]; then
        chown -R 999:999 "$redis_data_dir" "$redis_log_dir"
        chmod -R 777 "$redis_data_dir"
        chmod -R 777 "$redis_log_dir"
        print_success "Redis 数据目录权限已设置 (UID 999:999, 777)"
    else
        # 非 root 用户尝试使用 sudo（如果可用）
        if command -v sudo &> /dev/null; then
            sudo chown -R 999:999 "$redis_data_dir" "$redis_log_dir" 2>/dev/null && \
            sudo chmod -R 777 "$redis_data_dir" 2>/dev/null && \
            sudo chmod -R 777 "$redis_log_dir" 2>/dev/null && \
            print_success "Redis 数据目录权限已设置 (UID 999:999, 777)" || \
            print_warning "无法设置 Redis 目录权限，可能需要手动设置: sudo chmod -R 777 $redis_data_dir $redis_log_dir"
        else
            print_warning "无法设置 Redis 目录权限，请手动执行: sudo chmod -R 777 $redis_data_dir $redis_log_dir"
        fi
    fi
}

# 创建并设置 Kafka 数据目录权限
create_kafka_directories() {
    local kafka_data_dir="${SCRIPT_DIR}/mq_data/data"
    
    print_info "创建 Kafka 数据目录并设置权限..."
    
    # 检查文件系统是否可写
    local parent_dir=$(dirname "$kafka_data_dir")
    if ! check_filesystem_writable "$parent_dir"; then
        print_error "无法创建 Kafka 数据目录: $kafka_data_dir"
        print_error "原因: 父目录 $parent_dir 所在文件系统不可写"
        print_error "请检查文件系统挂载状态并解决只读问题"
        return 1
    fi
    
    # 创建目录
    local mkdir_output=""
    mkdir_output=$(mkdir -p "$kafka_data_dir" 2>&1)
    local mkdir_exit_code=$?
    
    if [ $mkdir_exit_code -ne 0 ]; then
        print_error "创建 Kafka 数据目录失败: $kafka_data_dir"
        print_error "错误信息: $mkdir_output"
        
        # 检查是否是只读文件系统错误
        if echo "$mkdir_output" | grep -qiE "read-only|readonly|read only|permission denied"; then
            print_error "检测到文件系统只读错误"
            echo ""
            print_error "文件系统挂载信息:"
            df -h "$parent_dir" 2>/dev/null || true
            echo ""
            print_error "请检查文件系统挂载状态并解决只读问题"
        fi
        return 1
    fi
    
    # Kafka 容器默认使用 UID 1000, GID 1000 (appuser 用户)
    # 如果当前用户有权限，则设置；否则只创建目录
    if [ "$EUID" -eq 0 ]; then
        chown -R 1000:1000 "$kafka_data_dir"
        chmod -R 777 "$kafka_data_dir"
        print_success "Kafka 数据目录权限已设置 (UID 1000:1000, 777)"
    else
        # 非 root 用户尝试使用 sudo（如果可用）
        if command -v sudo &> /dev/null; then
            sudo chown -R 1000:1000 "$kafka_data_dir" 2>/dev/null && \
            sudo chmod -R 777 "$kafka_data_dir" 2>/dev/null && \
            print_success "Kafka 数据目录权限已设置 (UID 1000:1000, 777)" || \
            print_warning "无法设置 Kafka 目录权限，可能需要手动设置: sudo chmod -R 777 $kafka_data_dir"
        else
            print_warning "无法设置 Kafka 目录权限，请手动执行: sudo chmod -R 777 $kafka_data_dir"
        fi
    fi
}

# 检查文件系统是否可写
check_filesystem_writable() {
    local test_path="$1"
    local test_file=""
    
    # 如果路径是目录，在目录内创建测试文件
    if [ -d "$test_path" ]; then
        test_file="${test_path}/.write_test_$$"
    else
        # 如果路径不存在，尝试创建父目录并测试
        local parent_dir=$(dirname "$test_path")
        if [ ! -d "$parent_dir" ]; then
            # 尝试创建父目录
            if ! mkdir -p "$parent_dir" 2>/dev/null; then
                return 1
            fi
        fi
        test_file="${parent_dir}/.write_test_$$"
    fi
    
    # 尝试创建测试文件
    if touch "$test_file" 2>/dev/null; then
        rm -f "$test_file" 2>/dev/null
        return 0
    else
        return 1
    fi
}

# 检查文件系统挂载状态
check_filesystem_mount_status() {
    local path="$1"
    
    # 获取路径所在的挂载点
    local mount_point=$(df "$path" 2>/dev/null | tail -1 | awk '{print $6}')
    local mount_info=$(df -h "$path" 2>/dev/null | tail -1)
    local filesystem=$(echo "$mount_info" | awk '{print $1}')
    local mount_options=""
    
    # 获取挂载选项
    if [ -f /proc/mounts ]; then
        mount_options=$(grep -E "^${filesystem}[[:space:]]" /proc/mounts 2>/dev/null | awk '{print $4}' | head -1 || echo "")
    fi
    
    # 检查是否包含 ro (read-only)
    if echo "$mount_options" | grep -qE "(^|,)ro(,|$)"; then
        return 1  # 只读
    fi
    
    return 0  # 可写
}


# 创建所有中间件的存储目录
create_all_storage_directories() {
    print_info "创建所有中间件存储目录..."
    
    # 首先检查脚本目录所在文件系统是否可写
    if ! check_filesystem_writable "$SCRIPT_DIR"; then
        print_error "文件系统只读错误：无法在 $SCRIPT_DIR 创建目录"
        echo ""
        print_error "检测到文件系统为只读状态，无法创建数据目录"
        echo ""
        
        # 检查挂载状态
        if ! check_filesystem_mount_status "$SCRIPT_DIR"; then
            print_error "文件系统挂载为只读模式"
            print_info "挂载信息:"
            df -h "$SCRIPT_DIR" 2>/dev/null | tail -1 || true
            echo ""
        fi
        
        print_warning "解决方案："
        echo ""
        print_info "1. 检查文件系统挂载状态："
        print_info "   mount | grep $(df "$SCRIPT_DIR" 2>/dev/null | tail -1 | awk '{print $1}')"
        echo ""
        print_info "2. 如果是只读挂载，需要重新挂载为可写："
        print_info "   sudo mount -o remount,rw $(df "$SCRIPT_DIR" 2>/dev/null | tail -1 | awk '{print $1}')"
        echo ""
        print_info "3. 或者将项目部署到可写的文件系统，例如："
        print_info "   - /home/用户名/easyaiot"
        print_info "   - /data/easyaiot"
        print_info "   - /var/lib/easyaiot"
        echo ""
        print_info "4. 检查磁盘空间是否已满："
        print_info "   df -h"
        echo ""
        print_error "无法继续安装，请先解决文件系统只读问题"
        exit 1
    fi
    
    # 定义所有需要创建的存储目录及其权限设置
    # 格式: "目录路径:UID:GID:权限"
    local storage_dirs=(
        "${SCRIPT_DIR}/standalone-logs:::"              # Nacos 日志（使用默认权限）
        "${SCRIPT_DIR}/db_data/data:999:999:777"       # PostgreSQL 数据
        "${SCRIPT_DIR}/db_data/log:999:999:777"        # PostgreSQL 日志
        "${SCRIPT_DIR}/taos_data/data:::"              # TDengine 数据（使用默认权限）
        "${SCRIPT_DIR}/taos_data/log:::"               # TDengine 日志（使用默认权限）
        "${SCRIPT_DIR}/redis_data/data:999:999:777"   # Redis 数据
        "${SCRIPT_DIR}/redis_data/logs:999:999:777"    # Redis 日志
        "${SCRIPT_DIR}/mq_data/data:1000:1000:777"    # Kafka 数据（uid=1000, gid=1000）
        "${SCRIPT_DIR}/minio_data/data:::"             # MinIO 数据（使用默认权限）
        "${SCRIPT_DIR}/minio_data/config:::"           # MinIO 配置（使用默认权限）
        "${SCRIPT_DIR}/srs_data/conf:::"               # SRS 配置（使用默认权限）
        "${SCRIPT_DIR}/srs_data/data:::"              # SRS 数据（使用默认权限）
        "${SCRIPT_DIR}/srs_data/playbacks:::"          # SRS 回放（使用默认权限）
        "${SCRIPT_DIR}/nodered_data/data:1000:1000:777" # NodeRED 数据
    )
    
    local created_count=0
    local total_count=${#storage_dirs[@]}
    local failed_dirs=()
    
    for dir_spec in "${storage_dirs[@]}"; do
        # 解析目录规格
        IFS=':' read -r dir_path uid gid perms <<< "$dir_spec"
        
        if [ -z "$dir_path" ]; then
            continue
        fi
        
        # 检查父目录是否可写
        local parent_dir=$(dirname "$dir_path")
        if ! check_filesystem_writable "$parent_dir"; then
            print_error "无法创建目录: $dir_path"
            print_error "原因: 父目录 $parent_dir 所在文件系统不可写"
            failed_dirs+=("$dir_path")
            continue
        fi
        
        # 创建目录
        local mkdir_output=""
        mkdir_output=$(mkdir -p "$dir_path" 2>&1)
        local mkdir_exit_code=$?
        
        if [ $mkdir_exit_code -eq 0 ]; then
            # 如果指定了 UID/GID，尝试设置权限
            if [ -n "$uid" ] && [ -n "$gid" ]; then
                if [ "$EUID" -eq 0 ]; then
                    chown -R "${uid}:${gid}" "$dir_path" 2>/dev/null || true
                    chmod -R 777 "$dir_path" 2>/dev/null || true
                elif command -v sudo &> /dev/null; then
                    sudo chown -R "${uid}:${gid}" "$dir_path" 2>/dev/null || true
                    sudo chmod -R 777 "$dir_path" 2>/dev/null || true
                fi
            else
                # 即使没有指定 UID/GID，也设置777权限
                if [ "$EUID" -eq 0 ]; then
                    chmod -R 777 "$dir_path" 2>/dev/null || true
                elif command -v sudo &> /dev/null; then
                    sudo chmod -R 777 "$dir_path" 2>/dev/null || true
                fi
            fi
            created_count=$((created_count + 1))
        else
            print_error "创建目录失败: $dir_path"
            print_error "错误信息: $mkdir_output"
            failed_dirs+=("$dir_path")
            
            # 检查是否是只读文件系统错误
            if echo "$mkdir_output" | grep -qiE "read-only|readonly|read only|permission denied"; then
                print_error "检测到文件系统只读错误"
                echo ""
                print_error "文件系统挂载信息:"
                df -h "$parent_dir" 2>/dev/null || true
                echo ""
                print_error "请检查文件系统挂载状态并解决只读问题"
                echo ""
            fi
        fi
    done
    
    # 统一设置所有已创建目录的777权限
    print_info "统一设置所有存储目录为777权限..."
    for dir_spec in "${storage_dirs[@]}"; do
        IFS=':' read -r dir_path uid gid perms <<< "$dir_spec"
        if [ -n "$dir_path" ] && [ -d "$dir_path" ]; then
            if [ "$EUID" -eq 0 ]; then
                chmod -R 777 "$dir_path" 2>/dev/null || true
            elif command -v sudo &> /dev/null; then
                sudo chmod -R 777 "$dir_path" 2>/dev/null || true
            fi
        fi
    done
    
    # 同时设置所有父目录为777权限
    local parent_dirs=(
        "${SCRIPT_DIR}/standalone-logs"
        "${SCRIPT_DIR}/db_data"
        "${SCRIPT_DIR}/taos_data"
        "${SCRIPT_DIR}/redis_data"
        "${SCRIPT_DIR}/mq_data"
        "${SCRIPT_DIR}/minio_data"
        "${SCRIPT_DIR}/srs_data"
        "${SCRIPT_DIR}/nodered_data"
        "${SCRIPT_DIR}/logs"
    )
    for parent_dir in "${parent_dirs[@]}"; do
        if [ -d "$parent_dir" ]; then
            if [ "$EUID" -eq 0 ]; then
                chmod -R 777 "$parent_dir" 2>/dev/null || true
            elif command -v sudo &> /dev/null; then
                sudo chmod -R 777 "$parent_dir" 2>/dev/null || true
            fi
        fi
    done
    
    if [ $created_count -eq $total_count ]; then
        print_success "所有存储目录已创建并设置为777权限（${created_count}/${total_count}）"
    else
        print_error "部分存储目录创建失败（${created_count}/${total_count}）"
        if [ ${#failed_dirs[@]} -gt 0 ]; then
            echo ""
            print_error "失败的目录列表:"
            for failed_dir in "${failed_dirs[@]}"; do
                print_error "  - $failed_dir"
            done
            echo ""
            print_error "这可能导致容器启动失败，请先解决文件系统问题"
            exit 1
        fi
    fi
}

# 准备 EMQX 容器和数据卷
prepare_emqx_volumes() {
    print_info "准备 EMQX 容器和数据卷..."
    
    # 检查 Docker 是否可用
    if ! docker ps &> /dev/null; then
        print_warning "无法访问 Docker，跳过 EMQX 容器清理"
        return 0
    fi
    
    # 检查是否存在旧的 EMQX 容器
    local old_container=$(docker ps -a --filter "name=emqx-server" --format "{{.Names}}" 2>/dev/null | head -n 1)
    
    if [ -n "$old_container" ]; then
        print_info "发现旧的 EMQX 容器: $old_container"
        
        # 停止容器
        if docker stop "$old_container" &> /dev/null; then
            print_info "已停止旧容器: $old_container"
        fi
        
        # 删除容器
        if docker rm -f "$old_container" &> /dev/null; then
            print_success "已删除旧容器: $old_container"
        else
            print_warning "删除旧容器失败: $old_container"
        fi
    else
        print_info "未发现旧的 EMQX 容器"
    fi
    
    # 清理旧的宿主机目录（如果存在，现在使用具名卷不再需要）
    local old_data_dir="${SCRIPT_DIR}/emqx_data"
    if [ -d "$old_data_dir" ]; then
        print_info "发现旧的 EMQX 数据目录: $old_data_dir"
        print_warning "注意：现在使用 Docker 具名卷，旧的宿主机目录可以删除"
        print_info "如需保留数据，请手动备份后再删除"
        
        # 询问是否删除旧目录（可选）
        # 为了自动化，这里默认不删除，只提示
        print_info "旧数据目录保留在: $old_data_dir（如需删除请手动执行: rm -rf $old_data_dir）"
    fi
    
    # 确保 Docker 具名卷已创建（Docker Compose 会自动创建）
    print_info "EMQX 将使用 Docker 具名卷存储数据（自动创建）"
    print_success "EMQX 容器和数据卷准备完成"
}

# 获取 Docker 网络网关 IP（用于容器访问宿主机服务）
get_docker_network_gateway() {
    local network_name="${1:-easyaiot-network}"
    local gateway_ip=""
    
    # 方法1: 如果网络已存在，直接获取网关IP
    if docker network inspect "$network_name" >/dev/null 2>&1; then
        gateway_ip=$(docker network inspect "$network_name" --format='{{range .IPAM.Config}}{{.Gateway}}{{end}}' 2>/dev/null | head -n 1)
        if [ -n "$gateway_ip" ] && [[ "$gateway_ip" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
            echo "$gateway_ip"
            return 0
        fi
    fi
    
    # 方法2: 如果网络不存在，尝试创建网络后获取
    if ! docker network inspect "$network_name" >/dev/null 2>&1; then
        if docker network create "$network_name" >/dev/null 2>&1; then
            gateway_ip=$(docker network inspect "$network_name" --format='{{range .IPAM.Config}}{{.Gateway}}{{end}}' 2>/dev/null | head -n 1)
            if [ -n "$gateway_ip" ] && [[ "$gateway_ip" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
                echo "$gateway_ip"
                return 0
            fi
        fi
    fi
    
    # 方法3: 使用默认Docker网关IP（通常是172.17.0.1或172.18.0.1）
    if command -v ip &> /dev/null; then
        gateway_ip=$(ip addr show docker0 2>/dev/null | grep "inet " | awk '{print $2}' | cut -d/ -f1)
        if [ -n "$gateway_ip" ] && [[ "$gateway_ip" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
            echo "$gateway_ip"
            return 0
        fi
    fi
    
    # 方法4: 使用常见的Docker网络网关IP
    echo "172.18.0.1"
    return 0
}

# 准备 SRS 配置文件
# 强制更新模式：无论配置文件是否存在，都重新生成并自动替换 IP 地址
prepare_srs_config() {
    local srs_config_source="${SCRIPT_DIR}/../srs/conf"
    local srs_config_target="${SCRIPT_DIR}/srs_data/conf"
    local srs_config_file="${srs_config_target}/docker.conf"
    
    print_info "准备 SRS 配置文件..."
    
    # 获取宿主机 IP 地址（用于VIDEO服务，如果VIDEO在宿主机运行）
    local host_ip=$(get_host_ip)
    if [ -z "$host_ip" ]; then
        print_warning "无法获取宿主机 IP，将使用 127.0.0.1（可能导致 VIDEO 模块回调失败）"
        host_ip="127.0.0.1"
    else
        print_info "检测到宿主机 IP: $host_ip"
    fi
    
    # 获取 Docker 网络网关 IP（用于Gateway服务，如果Gateway在宿主机运行）
    local gateway_ip=$(get_docker_network_gateway "easyaiot-network")
    if [ -z "$gateway_ip" ]; then
        print_warning "无法获取 Docker 网络网关 IP，将使用 172.18.0.1"
        gateway_ip="172.18.0.1"
    else
        print_info "检测到 Docker 网络网关 IP: $gateway_ip"
    fi
    
    # 创建目标目录
    mkdir -p "$srs_config_target"
    
    # 强制更新模式：无论配置文件是否存在，都重新生成
    print_info "重新获取 IP 地址并重新生成配置文件..."
    
    # 尝试从源目录复制配置文件
    if [ -d "$srs_config_source" ] && [ -f "$srs_config_source/docker.conf" ]; then
        print_info "从源目录复制 SRS 配置文件..."
        if cp -f "$srs_config_source/docker.conf" "$srs_config_file" 2>/dev/null; then
            # 替换配置文件中的 Gateway 地址（48080端口）- 用于访问宿主机上的Gateway服务
            sed -i -E "s|http://([0-9]{1,3}\.){3}[0-9]{1,3}:48080|http://${gateway_ip}:48080|g" "$srs_config_file"
            # 替换配置文件中的 VIDEO 地址（6000端口）- 用于访问宿主机上的VIDEO服务
            sed -i -E "s|http://([0-9]{1,3}\.){3}[0-9]{1,3}:6000|http://${host_ip}:6000|g" "$srs_config_file"
            print_info "已将配置文件中的 Gateway 地址更新为: $gateway_ip:48080"
            print_info "已将配置文件中的 VIDEO 地址更新为: $host_ip:6000"
            print_success "SRS 配置文件已复制并更新: $srs_config_source/docker.conf -> $srs_config_file"
            # 验证文件确实存在
            if [ -f "$srs_config_file" ]; then
                return 0
            fi
        else
            print_warning "无法复制 SRS 配置文件，将创建默认配置"
        fi
    else
        print_warning "源配置文件不存在: $srs_config_source/docker.conf，将创建默认配置"
    fi
    
    # 如果复制失败或源文件不存在，创建默认配置文件
    print_info "创建默认 SRS 配置文件..."
    cat > "$srs_config_file" << EOF
# SRS Docker 配置文件
# 用于 Docker 容器部署的 SRS 配置

listen              1935;
max_connections     1000;
daemon              on;
srs_log_tank        file;
srs_log_file        /data/srs.log;

http_server {
    enabled         on;
    listen          8080;
    dir             ./objs/nginx/html;
}

http_api {
    enabled         on;
    listen          1985;
    raw_api {
        enabled             on;
        allow_reload        on;
    }
}
stats {
    network         0;
}
rtc_server {
    enabled on;
    listen 8000;
    candidate *;
}

vhost __defaultVhost__ {
    http_remux {
        enabled     on;
        mount       [vhost]/[app]/[stream].flv;
    }
    rtc {
        enabled     on;
        rtmp_to_rtc on;
        rtc_to_rtmp on;
    }
    dvr {
        enabled             on;
        dvr_path            /data/playbacks/[app]/[stream]/[2006]/[01]/[02]/[timestamp].flv;
        dvr_plan            segment;
        dvr_duration        30;
        dvr_wait_keyframe   on;
    }
    http_hooks {
        enabled             on;
        on_dvr              http://${gateway_ip}:48080/admin-api/video/camera/callback/on_dvr;
        on_publish          http://${gateway_ip}:48080/admin-api/video/camera/callback/on_publish;
    }
}
EOF
    
    # 验证文件是否创建成功
    if [ -f "$srs_config_file" ]; then
        print_success "默认 SRS 配置文件已创建: $srs_config_file"
        print_info "  - Gateway 回调地址: http://${gateway_ip}:48080/admin-api/video/camera/callback/*"
        return 0
    else
        print_error "无法创建 SRS 配置文件: $srs_config_file"
        return 1
    fi
}

# 检查docker-compose.yml是否存在
check_compose_file() {
    if [ ! -f "$COMPOSE_FILE" ]; then
        print_error "docker-compose.yml文件不存在: $COMPOSE_FILE"
        exit 1
    fi
}

# 等待 PostgreSQL 服务就绪
wait_for_postgresql() {
    local max_attempts=60
    local attempt=0
    
    print_info "等待 PostgreSQL 服务就绪..."
    while [ $attempt -lt $max_attempts ]; do
        # 检查容器是否在运行
        if ! docker ps --filter "name=postgres-server" --format "{{.Names}}" | grep -q "postgres-server"; then
            if [ $attempt -eq 0 ]; then
                print_warning "PostgreSQL 容器未运行，等待启动..."
            fi
            attempt=$((attempt + 1))
            sleep 2
            continue
        fi
        
        # 检查服务是否就绪
        if docker exec postgres-server pg_isready -U postgres > /dev/null 2>&1; then
            # 额外等待一下，确保数据库完全初始化
            sleep 2
            print_success "PostgreSQL 服务已就绪"
            return 0
        fi
        attempt=$((attempt + 1))
        sleep 2
    done
    
    print_error "PostgreSQL 服务未就绪"
    return 1
}

# 重置 PostgreSQL 密码（确保密码与配置一致）
reset_postgresql_password() {
    print_section "重置 PostgreSQL 密码"
    
    # 等待 PostgreSQL 就绪（增加等待时间，确保数据库完全初始化）
    if ! wait_for_postgresql; then
        print_warning "PostgreSQL 未就绪，跳过密码重置"
        return 1
    fi
    
    # 额外等待，确保数据库完全就绪
    print_info "等待数据库完全初始化..."
    sleep 5
    
    # 从 docker-compose.yml 中读取配置的密码
    local target_password="iot45722414822"
    
    print_info "正在重置 postgres 用户密码为: $target_password"
    
    # 尝试通过容器内部重置密码
    # 方法1: 使用本地连接（不需要密码，通过 Unix socket）
    local reset_attempts=0
    local max_reset_attempts=10
    local reset_success=0
    
    while [ $reset_attempts -lt $max_reset_attempts ] && [ $reset_success -eq 0 ]; do
        # 尝试重置密码（使用本地连接，不需要密码）
        local reset_output=$(docker exec postgres-server psql -U postgres -d postgres -c "ALTER USER postgres WITH PASSWORD '$target_password';" 2>&1)
        local reset_exit_code=$?
        
        if [ $reset_exit_code -eq 0 ]; then
            print_success "PostgreSQL 密码重置成功"
            reset_success=1
            
            # 重新加载配置
            docker exec postgres-server psql -U postgres -d postgres -c "SELECT pg_reload_conf();" > /dev/null 2>&1 || true
            
            # 验证密码是否正确设置（使用新密码测试）
            sleep 3
            local verify_output=$(docker exec postgres-server psql -U postgres -d postgres -c "SELECT version();" 2>&1)
            local verify_exit_code=$?
            
            if [ $verify_exit_code -eq 0 ]; then
                print_success "PostgreSQL 密码验证通过"
                return 0
            else
                print_warning "密码重置成功，但验证时出现问题"
                print_info "验证输出: $verify_output"
                # 即使验证失败，也认为重置成功（可能是其他原因导致的验证失败）
                return 0
            fi
        else
            reset_attempts=$((reset_attempts + 1))
            if [ $reset_attempts -lt $max_reset_attempts ]; then
                print_warning "密码重置失败，正在重试 ($reset_attempts/$max_reset_attempts)..."
                print_info "错误信息: $reset_output"
                sleep 5
            fi
        fi
    done
    
    if [ $reset_success -eq 0 ]; then
        print_error "PostgreSQL 密码重置失败（已重试 $max_reset_attempts 次）"
        print_info "可能的原因："
        print_info "  1. 数据库正在初始化中，请稍后重试"
        print_info "  2. 容器权限问题"
        print_info "  3. 数据库数据目录损坏"
        echo ""
        print_info "手动修复命令："
        print_info "  docker exec postgres-server psql -U postgres -d postgres -c \"ALTER USER postgres WITH PASSWORD '$target_password';\""
        print_info "或者重启容器后重试："
        print_info "  docker restart postgres-server"
        print_info "  sleep 10"
        print_info "  docker exec postgres-server psql -U postgres -d postgres -c \"ALTER USER postgres WITH PASSWORD '$target_password';\""
        return 1
    fi
    
    return 0
}

# 确保 PostgreSQL 密码正确（可以在任何时候调用，用于修复密码问题）
ensure_postgresql_password() {
    print_section "确保 PostgreSQL 密码正确"
    
    # 检查容器是否在运行
    if ! docker ps --filter "name=postgres-server" --format "{{.Names}}" | grep -q "postgres-server"; then
        print_warning "PostgreSQL 容器未运行，无法检查密码"
        return 1
    fi
    
    # 等待 PostgreSQL 就绪
    if ! wait_for_postgresql; then
        print_warning "PostgreSQL 未就绪，无法检查密码"
        return 1
    fi
    
    local target_password="iot45722414822"
    
    # 测试当前密码是否正确
    print_info "测试当前 PostgreSQL 密码..."
    
    # 方法1: 使用环境变量测试密码（如果容器支持）
    local test_result=$(docker exec -e PGPASSWORD="$target_password" postgres-server psql -U postgres -d postgres -c "SELECT 1;" 2>&1)
    local test_exit_code=$?
    
    if [ $test_exit_code -eq 0 ]; then
        print_success "PostgreSQL 密码正确，无需重置"
        return 0
    fi
    
    # 方法2: 使用本地连接测试（不需要密码）
    local local_test=$(docker exec postgres-server psql -U postgres -d postgres -c "SELECT 1;" 2>&1)
    local local_test_exit_code=$?
    
    if [ $local_test_exit_code -eq 0 ]; then
        # 本地连接成功，说明可以通过本地连接重置密码
        print_info "可以通过本地连接重置密码，正在重置..."
        if reset_postgresql_password; then
            return 0
        else
            return 1
        fi
    else
        print_warning "无法通过本地连接访问数据库"
        print_info "错误信息: $local_test"
        print_info "尝试重置密码..."
        if reset_postgresql_password; then
            return 0
        else
            return 1
        fi
    fi
}

# 配置 PostgreSQL pg_hba.conf 允许从宿主机连接
configure_postgresql_pg_hba() {
    print_section "配置 PostgreSQL pg_hba.conf"
    
    # 等待 PostgreSQL 就绪
    if ! wait_for_postgresql; then
        print_warning "PostgreSQL 未就绪，跳过 pg_hba.conf 配置"
        return 1
    fi
    
    print_info "配置 pg_hba.conf 以允许从宿主机连接..."
    
    # 在容器内读取当前的 pg_hba.conf
    local pg_hba_path="/var/lib/postgresql/data/pg_hba.conf"
    local pg_hba_backup_path="/var/lib/postgresql/data/pg_hba.conf.backup"
    
    # 先备份原文件
    if docker exec postgres-server cp "$pg_hba_path" "$pg_hba_backup_path" 2>/dev/null; then
        print_info "已备份 pg_hba.conf"
    fi
    
    # 检查是否已经配置了允许所有主机连接的规则
    local has_host_all=$(docker exec postgres-server grep -E "^host\s+all\s+all\s+0\.0\.0\.0/0\s+md5" "$pg_hba_path" 2>/dev/null || echo "")
    
    if [ -n "$has_host_all" ]; then
        print_info "pg_hba.conf 已包含允许所有主机连接的配置"
    else
        print_info "添加允许所有主机连接的配置..."
        
        # 在容器内添加配置（使用 echo 命令）
        if docker exec postgres-server sh -c "echo '' >> $pg_hba_path && echo '# 允许从宿主机和所有网络连接（由安装脚本自动添加）' >> $pg_hba_path && echo 'host    all             all             0.0.0.0/0               md5' >> $pg_hba_path && echo 'host    all             all             ::/0                    md5' >> $pg_hba_path" 2>/dev/null; then
            print_success "已添加允许所有主机连接的配置"
        else
            print_warning "添加配置时出现问题，尝试使用另一种方法..."
            
            # 备用方法：使用临时文件
            local temp_file=$(mktemp)
            cat > "$temp_file" << 'EOF'

# 允许从宿主机和所有网络连接（由安装脚本自动添加）
host    all             all             0.0.0.0/0               md5
host    all             all             ::/0                    md5
EOF
            if docker cp "$temp_file" postgres-server:/tmp/pg_hba_append.conf 2>/dev/null && \
               docker exec postgres-server sh -c "cat /tmp/pg_hba_append.conf >> $pg_hba_path && rm /tmp/pg_hba_append.conf" 2>/dev/null; then
                print_success "已通过临时文件添加配置"
            else
                print_error "无法添加配置，请手动检查 pg_hba.conf"
                rm -f "$temp_file"
                return 1
            fi
            rm -f "$temp_file"
        fi
    fi
    
    # 检查 postgresql.conf 配置（注意：listen_addresses 的修改需要重启容器才能生效）
    print_info "检查 postgresql.conf 配置..."
    local postgresql_conf_path="/var/lib/postgresql/data/postgresql.conf"
    local listen_addresses=$(docker exec postgres-server grep -E "^listen_addresses\s*=" "$postgresql_conf_path" 2>/dev/null | head -1 || echo "")
    
    # PostgreSQL 容器默认应该已经配置为监听所有接口
    # 这里只做检查，不修改（因为修改需要重启容器）
    if [ -n "$listen_addresses" ]; then
        if echo "$listen_addresses" | grep -q "'\*'"; then
            print_info "listen_addresses 已正确配置为 '*'"
        else
            print_warning "listen_addresses 配置可能不正确: $listen_addresses"
            print_info "PostgreSQL 容器默认应该监听所有接口，如果连接有问题，请检查容器配置"
        fi
    else
        print_info "未找到 listen_addresses 配置（将使用默认值，通常为 '*'）"
    fi
    
    # 重新加载配置
    print_info "重新加载 PostgreSQL 配置..."
    if docker exec postgres-server psql -U postgres -d postgres -c "SELECT pg_reload_conf();" > /dev/null 2>&1; then
        print_success "PostgreSQL 配置已重新加载"
        
        # 验证配置是否生效（等待一下让配置生效）
        sleep 2
        
        # 测试从宿主机连接（如果 psql 可用）
        if command -v psql &> /dev/null; then
            local test_password="iot45722414822"
            export PGPASSWORD="$test_password"
            if psql -h 127.0.0.1 -p 5432 -U postgres -d postgres -c "SELECT 1;" > /dev/null 2>&1; then
                print_success "宿主机连接测试成功"
                unset PGPASSWORD
                return 0
            else
                print_warning "宿主机连接测试失败（可能需要检查防火墙或网络配置）"
                unset PGPASSWORD
            fi
        else
            print_info "未安装 psql 客户端，跳过连接测试"
        fi
        
        return 0
    else
        print_warning "无法重新加载 PostgreSQL 配置（可能需要重启容器）"
        print_info "如果连接仍有问题，请重启 PostgreSQL 容器: docker restart postgres-server"
        return 1
    fi
}

# 配置 PostgreSQL max_connections（最大连接数）
configure_postgresql_max_connections() {
    print_section "配置 PostgreSQL 最大连接数"
    
    # 等待 PostgreSQL 就绪
    if ! wait_for_postgresql; then
        print_warning "PostgreSQL 未就绪，跳过 max_connections 配置"
        return 1
    fi
    
    # 目标最大连接数（可根据需要调整）
    local target_max_connections=10240
    
    print_info "配置 PostgreSQL max_connections 为: $target_max_connections"
    
    # 检查当前 max_connections 配置
    local current_max_conn=$(docker exec postgres-server psql -U postgres -d postgres -t -c "SHOW max_connections;" 2>/dev/null | tr -d ' ' || echo "")
    
    if [ -n "$current_max_conn" ] && [ "$current_max_conn" = "$target_max_connections" ]; then
        print_success "PostgreSQL max_connections 已正确配置为: $target_max_connections"
        return 0
    fi
    
    if [ -n "$current_max_conn" ]; then
        print_info "当前 max_connections: $current_max_conn，将更新为: $target_max_connections"
    fi
    
    # 方法1: 通过修改 postgresql.conf 文件（需要重启容器才能生效）
    local postgresql_conf_path="/var/lib/postgresql/data/postgresql.conf"
    local pgdata_dir="/var/lib/postgresql/data/pgdata"
    
    # 如果使用 PGDATA 子目录，配置文件路径需要调整
    if docker exec postgres-server test -f "$pgdata_dir/postgresql.conf" 2>/dev/null; then
        postgresql_conf_path="$pgdata_dir/postgresql.conf"
    fi
    
    # 备份配置文件
    if docker exec postgres-server test -f "$postgresql_conf_path" 2>/dev/null; then
        docker exec postgres-server cp "$postgresql_conf_path" "${postgresql_conf_path}.backup.$(date +%Y%m%d_%H%M%S)" 2>/dev/null || true
        print_info "已备份 postgresql.conf"
    fi
    
    # 检查配置文件中是否已有 max_connections 设置
    local has_max_conn=$(docker exec postgres-server grep -E "^max_connections\s*=" "$postgresql_conf_path" 2>/dev/null || echo "")
    
    if [ -n "$has_max_conn" ]; then
        # 更新现有配置
        print_info "更新现有 max_connections 配置..."
        if docker exec postgres-server sed -i "s/^max_connections\s*=.*/max_connections = $target_max_connections/" "$postgresql_conf_path" 2>/dev/null; then
            print_success "已更新 postgresql.conf 中的 max_connections 配置"
        else
            print_warning "更新配置文件失败，尝试使用 SQL 命令设置..."
            # 使用 ALTER SYSTEM 命令（PostgreSQL 9.4+）
            if docker exec postgres-server psql -U postgres -d postgres -c "ALTER SYSTEM SET max_connections = $target_max_connections;" > /dev/null 2>&1; then
                print_success "已通过 ALTER SYSTEM 命令设置 max_connections"
                # 重新加载配置
                docker exec postgres-server psql -U postgres -d postgres -c "SELECT pg_reload_conf();" > /dev/null 2>&1 || true
                print_warning "注意：max_connections 的修改需要重启 PostgreSQL 容器才能完全生效"
            else
                print_error "无法设置 max_connections"
                return 1
            fi
        fi
    else
        # 添加新配置
        print_info "添加 max_connections 配置到 postgresql.conf..."
        if docker exec postgres-server sh -c "echo '' >> $postgresql_conf_path && echo '# 最大连接数配置（由安装脚本自动添加）' >> $postgresql_conf_path && echo 'max_connections = $target_max_connections' >> $postgresql_conf_path" 2>/dev/null; then
            print_success "已添加 max_connections 配置到 postgresql.conf"
        else
            # 使用 ALTER SYSTEM 命令作为备用方案
            print_warning "添加配置到文件失败，尝试使用 ALTER SYSTEM 命令..."
            if docker exec postgres-server psql -U postgres -d postgres -c "ALTER SYSTEM SET max_connections = $target_max_connections;" > /dev/null 2>&1; then
                print_success "已通过 ALTER SYSTEM 命令设置 max_connections"
                # 重新加载配置
                docker exec postgres-server psql -U postgres -d postgres -c "SELECT pg_reload_conf();" > /dev/null 2>&1 || true
                print_warning "注意：max_connections 的修改需要重启 PostgreSQL 容器才能完全生效"
            else
                print_error "无法设置 max_connections"
                return 1
            fi
        fi
    fi
    
    # 注意：max_connections 需要重启容器才能生效
    print_warning "重要提示：max_connections 的修改需要重启 PostgreSQL 容器才能完全生效"
    print_info "当前配置已更新，但新值将在容器重启后生效"
    print_info "如需立即生效，请执行: docker restart postgres-server"
    
    # 验证配置（虽然需要重启才能生效，但可以检查配置是否正确写入）
    sleep 2
    local verify_max_conn=$(docker exec postgres-server psql -U postgres -d postgres -t -c "SHOW max_connections;" 2>/dev/null | tr -d ' ' || echo "")
    
    if [ -n "$verify_max_conn" ]; then
        if [ "$verify_max_conn" = "$target_max_connections" ]; then
            print_success "max_connections 配置已生效: $verify_max_conn"
        else
            print_info "当前 max_connections: $verify_max_conn（配置已更新，重启容器后将变为: $target_max_connections）"
        fi
    fi
    
    return 0
}

# 等待 Nacos 服务就绪
wait_for_nacos() {
    local max_attempts=60
    local attempt=0
    
    print_info "等待 Nacos 服务就绪..."
    while [ $attempt -lt $max_attempts ]; do
        if curl -s --connect-timeout 2 "http://localhost:8848/nacos/actuator/health" > /dev/null 2>&1; then
            print_success "Nacos 服务已就绪"
            return 0
        fi
        attempt=$((attempt + 1))
        sleep 2
    done
    
    print_error "Nacos 服务未就绪"
    return 1
}

# 等待 MinIO 服务就绪
wait_for_minio() {
    local max_attempts=60
    local attempt=0
    
    print_info "等待 MinIO 服务就绪..."
    while [ $attempt -lt $max_attempts ]; do
        if curl -s --connect-timeout 2 "http://localhost:9000/minio/health/live" > /dev/null 2>&1; then
            print_success "MinIO 服务已就绪"
            return 0
        fi
        attempt=$((attempt + 1))
        sleep 2
    done
    
    print_error "MinIO 服务未就绪"
    return 1
}

# 等待 Kafka 服务就绪
wait_for_kafka() {
    local max_attempts=90  # 增加等待次数（从60增加到90，总共3分钟）
    local attempt=0
    
    print_info "等待 Kafka 服务就绪..."
    
    # 首先检查容器是否存在
    if ! docker ps -a --filter "name=kafka-server" --format "{{.Names}}" | grep -q "kafka-server"; then
        print_error "Kafka 容器 kafka-server 不存在"
        return 1
    fi
    
    # 检查容器是否在运行
    local container_status=$(docker ps --filter "name=kafka-server" --format "{{.Status}}" 2>/dev/null | head -1 || echo "")
    if [ -z "$container_status" ]; then
        print_warning "Kafka 容器未运行，尝试启动..."
        docker start kafka-server > /dev/null 2>&1 || true
        sleep 5
    fi
    
    while [ $attempt -lt $max_attempts ]; do
        # 检查容器是否在运行
        if ! docker ps --filter "name=kafka-server" --format "{{.Names}}" | grep -q "kafka-server"; then
            if [ $attempt -eq 0 ]; then
                print_warning "Kafka 容器未运行，等待启动..."
            fi
            attempt=$((attempt + 1))
            sleep 2
            continue
        fi
        
        # 方法1: 使用 kafka-broker-api-versions 命令测试（推荐）
        local check_result=""
        local check_error=""
        check_result=$(docker exec kafka-server kafka-broker-api-versions.sh --bootstrap-server localhost:9092 2>&1)
        local check_exit_code=$?
        
        if [ $check_exit_code -eq 0 ]; then
            print_success "Kafka 服务已就绪"
            return 0
        fi
        
        # 方法2: 如果方法1失败，尝试使用 kafka-topics.sh 命令
        if [ $check_exit_code -ne 0 ]; then
            check_result=$(docker exec kafka-server kafka-topics.sh --bootstrap-server localhost:9092 --list 2>&1)
            check_exit_code=$?
            if [ $check_exit_code -eq 0 ]; then
                print_success "Kafka 服务已就绪（通过 topics 命令验证）"
                return 0
            fi
        fi
        
        # 显示进度（每10次显示一次）
        if [ $((attempt % 10)) -eq 0 ] && [ $attempt -gt 0 ]; then
            print_info "等待中... ($attempt/$max_attempts) - 检查容器状态..."
            # 显示容器状态
            local container_info=$(docker ps --filter "name=kafka-server" --format "{{.Status}}" 2>/dev/null || echo "未运行")
            print_info "容器状态: $container_info"
        fi
        
        attempt=$((attempt + 1))
        sleep 2
    done
    
    # 超时后输出详细错误信息
    print_error "Kafka 服务未就绪（等待超时）"
    
    # 检查容器状态
    local container_status=$(docker ps -a --filter "name=kafka-server" --format "{{.Status}}" 2>/dev/null | head -1 || echo "")
    if [ -n "$container_status" ]; then
        print_info "容器状态: $container_status"
    else
        print_error "无法获取容器状态"
    fi
    
    # 输出容器日志的最后几行
    print_info "查看 Kafka 容器日志（最后20行）..."
    docker logs --tail 20 kafka-server 2>&1 | while IFS= read -r line; do
        print_info "  $line"
    done || print_warning "无法获取容器日志"
    
    # 提供诊断建议
    echo ""
    print_warning "诊断建议："
    print_info "1. 检查容器是否正常运行: docker ps | grep kafka"
    print_info "2. 查看完整日志: docker logs kafka-server"
    print_info "3. 检查端口是否被占用: ss -tlnp | grep 9092"
    print_info "4. 尝试手动启动: docker start kafka-server"
    print_info "5. 检查数据目录权限: ls -la .scripts/docker/mq_data/data"
    
    return 1
}


# 等待 TDengine 服务就绪
wait_for_tdengine() {
    local max_attempts=60
    local attempt=0
    
    print_info "等待 TDengine 服务就绪..."
    while [ $attempt -lt $max_attempts ]; do
        # 使用 taos 命令测试连接
        if docker exec tdengine-server taos -h localhost -s "select 1;" > /dev/null 2>&1; then
            print_success "TDengine 服务已就绪"
            return 0
        fi
        attempt=$((attempt + 1))
        sleep 2
    done
    
    print_error "TDengine 服务未就绪"
    return 1
}

# 检查 TDengine 数据库是否存在
check_tdengine_database() {
    local db_name=$1
    
    # 检查数据库是否存在（通过查询系统数据库）
    local result=$(docker exec tdengine-server taos -h localhost -s "show databases;" 2>/dev/null | grep -w "$db_name" || echo "")
    if [ -n "$result" ]; then
        return 0  # 数据库存在
    else
        return 1  # 数据库不存在
    fi
}

# 创建 TDengine 数据库
create_tdengine_database() {
    local db_name=$1
    
    print_info "创建 TDengine 数据库: $db_name"
    
    # 检查数据库是否已存在
    if check_tdengine_database "$db_name"; then
        print_info "TDengine 数据库 $db_name 已存在，跳过创建"
        return 0
    fi
    
    # 创建数据库（使用 if not exists 避免重复创建错误）
    local output=$(docker exec tdengine-server taos -h localhost -s "create database if not exists $db_name;" 2>&1)
    local exit_code=$?
    
    if [ $exit_code -eq 0 ]; then
        print_success "TDengine 数据库 $db_name 创建成功"
        return 0
    else
        # 检查是否是因为数据库已存在（某些情况下可能检测不到）
        if echo "$output" | grep -qiE "(already exists|exist)"; then
            print_info "TDengine 数据库 $db_name 已存在（检测到已存在消息）"
            return 0
        else
            print_error "TDengine 数据库 $db_name 创建失败: $output"
            return 1
        fi
    fi
}

# 执行 TDengine SQL 脚本
execute_tdengine_sql_script() {
    local db_name=$1
    local sql_file=$2
    local error_log=$(mktemp)
    
    if [ ! -f "$sql_file" ]; then
        print_error "SQL 文件不存在: $sql_file"
        return 1
    fi
    
    print_info "执行 TDengine SQL 脚本: $sql_file -> 数据库: $db_name"
    
    # TDengine 执行 SQL 脚本的方式：
    # 方法1: 将 SQL 文件复制到容器内执行（推荐）
    # 方法2: 通过标准输入传递 SQL 内容
    
    # 使用标准输入方式执行 SQL 脚本
    # 注意：SQL 文件中已经包含了 CREATE DATABASE IF NOT EXISTS 语句
    # 但为了确保在正确的数据库中执行，我们在开头添加 USE 语句
    
    # 创建临时 SQL 内容，添加 USE 语句（如果 SQL 文件中没有指定数据库）
    local temp_sql_content=$(mktemp)
    {
        echo "USE $db_name;"
        cat "$sql_file"
    } > "$temp_sql_content"
    
    # 通过标准输入执行 SQL 脚本
    # TDengine 的 taos 命令可以通过标准输入读取 SQL
    local output=$(docker exec -i tdengine-server taos -h localhost < "$temp_sql_content" 2>"$error_log")
    local exit_code=$?
    
    # 清理临时文件
    rm -f "$temp_sql_content"
    
    if [ $exit_code -eq 0 ]; then
        print_success "TDengine SQL 脚本执行成功: $sql_file"
        rm -f "$error_log"
        return 0
    else
        # 检查错误日志，忽略常见的非致命错误
        local error_content=$(cat "$error_log" 2>/dev/null || echo "")
        rm -f "$error_log"
        
        # TDengine 常见的非致命错误信息
        if [ -z "$error_content" ] || echo "$error_content" | grep -qiE "(warning|notice|already exists|does not exist|DB already exists|Table already exists|STable already exists)"; then
            print_success "TDengine SQL 脚本执行完成: $sql_file (可能有警告，但已忽略)"
            return 0
        else
            print_warning "TDengine SQL 脚本执行可能有问题: $sql_file"
            print_info "错误信息: $error_content"
            # 即使有错误也继续，因为某些 SQL 文件可能包含错误处理
            return 0
        fi
    fi
}

# 初始化 TDengine 数据库和超级表
init_tdengine() {
    print_section "初始化 TDengine 数据库和超级表"
    
    # 等待 TDengine 就绪
    if ! wait_for_tdengine; then
        print_error "TDengine 未就绪，无法初始化数据库"
        return 1
    fi
    
    # 定义需要创建的数据库列表
    local databases=("iot_device")
    local success_count=0
    local total_count=${#databases[@]}
    
    # 创建数据库
    for db_name in "${databases[@]}"; do
        if create_tdengine_database "$db_name"; then
            success_count=$((success_count + 1))
        fi
        echo ""
    done
    
    echo ""
    print_section "TDengine 初始化结果"
    echo "成功: ${GREEN}$success_count${NC} / $total_count"
    
    if [ $success_count -eq $total_count ]; then
        print_success "所有 TDengine 数据库初始化完成！"
        
        # 执行超级表初始化 SQL 脚本
        echo ""
        print_section "初始化 TDengine 超级表"
        
        # 查找 SQL 脚本文件路径
        # SCRIPT_DIR 是 .scripts/docker/，SQL 文件在 .scripts/tdengine/
        local sql_file=""
        
        # 方法1: 从脚本目录的父目录查找（.scripts/tdengine/）
        local script_parent_dir=$(cd "${SCRIPT_DIR}/.." && pwd 2>/dev/null || echo "")
        if [ -n "$script_parent_dir" ]; then
            sql_file="${script_parent_dir}/tdengine/tdengine_super_tables.sql"
        fi
        
        # 方法2: 如果方法1失败，尝试从项目根目录查找
        if [ -z "$sql_file" ] || [ ! -f "$sql_file" ]; then
            local project_root=$(cd "${SCRIPT_DIR}/../.." && pwd 2>/dev/null || echo "")
            if [ -n "$project_root" ]; then
                sql_file="${project_root}/.scripts/tdengine/tdengine_super_tables.sql"
            fi
        fi
        
        # 方法3: 尝试其他可能的路径
        if [ -z "$sql_file" ] || [ ! -f "$sql_file" ]; then
            local possible_paths=(
                "${SCRIPT_DIR}/../tdengine/tdengine_super_tables.sql"
                "${SCRIPT_DIR}/../../.scripts/tdengine/tdengine_super_tables.sql"
                "$(dirname "${SCRIPT_DIR}")/tdengine/tdengine_super_tables.sql"
            )
            
            for path in "${possible_paths[@]}"; do
                if [ -f "$path" ]; then
                    sql_file="$path"
                    break
                fi
            done
        fi
        
        if [ -f "$sql_file" ]; then
            print_info "找到 SQL 脚本文件: $sql_file"
            
            # 为每个数据库执行 SQL 脚本
            for db_name in "${databases[@]}"; do
                if execute_tdengine_sql_script "$db_name" "$sql_file"; then
                    print_success "数据库 $db_name 的超级表初始化完成"
                else
                    print_warning "数据库 $db_name 的超级表初始化可能存在问题"
                fi
            done
        else
            print_warning "未找到 TDengine 超级表 SQL 脚本文件"
            print_info "尝试的路径:"
            for path in "${possible_paths[@]}"; do
                print_info "  - $path"
            done
            print_info "  - $sql_file"
            print_warning "将跳过超级表初始化，超级表将在应用启动时根据产品服务动态创建"
        fi
        
        return 0
    else
        print_warning "部分 TDengine 数据库初始化失败"
        return 1
    fi
}

# 检查数据库是否已初始化（通过检查表数量）
check_database_initialized() {
    local db_name=$1
    
    # 检查数据库是否存在
    if ! docker exec postgres-server psql -U postgres -lqt | cut -d \| -f 1 | grep -qw "$db_name"; then
        return 1  # 数据库不存在
    fi
    
    # 检查数据库中是否有表（表数量 > 0 表示已初始化）
    local table_count=$(docker exec postgres-server psql -U postgres -d "$db_name" -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public';" 2>/dev/null | tr -d ' ')
    
    if [ -n "$table_count" ] && [ "$table_count" -gt 0 ] 2>/dev/null; then
        return 0  # 数据库已初始化
    else
        return 1  # 数据库未初始化
    fi
}

# 创建数据库
create_database() {
    local db_name=$1
    
    print_info "创建数据库: $db_name"
    
    if docker exec postgres-server psql -U postgres -lqt | cut -d \| -f 1 | grep -qw "$db_name"; then
        print_info "数据库 $db_name 已存在，跳过创建"
        return 0
    fi
    
    if docker exec postgres-server psql -U postgres -c "CREATE DATABASE \"$db_name\";" > /dev/null 2>&1; then
        print_success "数据库 $db_name 创建成功"
        return 0
    else
        print_error "数据库 $db_name 创建失败"
        return 1
    fi
}

# 执行 SQL 初始化脚本
execute_sql_script() {
    local db_name=$1
    local sql_file=$2
    local error_log=$(mktemp)
    
    if [ ! -f "$sql_file" ]; then
        print_error "SQL 文件不存在: $sql_file"
        return 1
    fi
    
    print_info "执行 SQL 脚本: $sql_file -> 数据库: $db_name"
    
    # 执行 SQL 脚本，捕获错误输出
    if docker exec -i postgres-server psql -U postgres -d "$db_name" < "$sql_file" > /dev/null 2>"$error_log"; then
        print_success "SQL 脚本执行成功: $sql_file"
        rm -f "$error_log"
        return 0
    else
        # 检查错误日志，忽略常见的非致命错误
        local error_content=$(cat "$error_log" 2>/dev/null || echo "")
        rm -f "$error_log"
        
        # 如果错误日志为空或只包含警告，认为成功
        if [ -z "$error_content" ] || echo "$error_content" | grep -qiE "(warning|notice|already exists|does not exist)"; then
            print_success "SQL 脚本执行完成: $sql_file (可能有警告，但已忽略)"
            return 0
        else
            print_warning "SQL 脚本执行可能有问题: $sql_file"
            print_info "错误信息: $error_content"
            # 即使有错误也继续，因为某些 SQL 文件可能包含错误处理
            return 0
        fi
    fi
}


# 初始化 MinIO 的 Python 脚本（临时文件）
create_minio_init_script() {
    local script_file=$(mktemp)
    cat > "$script_file" << 'PYTHON_SCRIPT'
#!/usr/bin/env python3
import sys
import os
from minio import Minio
from minio.error import S3Error
import mimetypes

def init_minio_buckets_and_upload():
    # MinIO 配置
    minio_endpoint = "localhost:9000"
    minio_access_key = "minioadmin"
    minio_secret_key = "basiclab@iot975248395"
    minio_secure = False
    
    # 存储桶列表
    buckets = ["dataset", "datasets", "export-bucket", "inference-inputs", "inference-results", "models", "snap-space", "alert-images"]
    
    # 数据集目录映射: (bucket_name, directory_path, object_prefix)
    # 参数格式: bucket1:dir1:prefix1 bucket2:dir2:prefix2 ...
    upload_tasks = []
    if len(sys.argv) > 1:
        for arg in sys.argv[1:]:
            if ':' in arg:
                parts = arg.split(':')
                if len(parts) >= 2:
                    bucket_name = parts[0]
                    dir_path = parts[1]
                    prefix = parts[2] if len(parts) > 2 else ""
                    upload_tasks.append((bucket_name, dir_path, prefix))
    
    try:
        # 创建 MinIO 客户端
        client = Minio(
            minio_endpoint,
            access_key=minio_access_key,
            secret_key=minio_secret_key,
            secure=minio_secure
        )
        
        # 创建存储桶
        created_buckets = 0
        for bucket_name in buckets:
            try:
                if client.bucket_exists(bucket_name):
                    print(f"BUCKET_EXISTS:{bucket_name}")
                else:
                    client.make_bucket(bucket_name)
                    print(f"BUCKET_CREATED:{bucket_name}")
                    created_buckets += 1
                    
                    # 设置存储桶策略为公开读写
                    # 注意：存储桶操作和对象操作需要分开配置
                    policy = {
                        "Version": "2012-10-17",
                        "Statement": [
                            {
                                "Effect": "Allow",
                                "Principal": "*",
                                "Action": [
                                    "s3:GetBucketLocation",
                                    "s3:ListBucket",
                                    "s3:ListBucketMultipartUploads"
                                ],
                                "Resource": [f"arn:aws:s3:::{bucket_name}"]
                            },
                            {
                                "Effect": "Allow",
                                "Principal": "*",
                                "Action": [
                                    "s3:ListMultipartUploadParts",
                                    "s3:PutObject",
                                    "s3:GetObject",
                                    "s3:DeleteObject",
                                    "s3:AbortMultipartUpload"
                                ],
                                "Resource": [f"arn:aws:s3:::{bucket_name}/*"]
                            }
                        ]
                    }
                    import json
                    client.set_bucket_policy(bucket_name, json.dumps(policy))
            except S3Error as e:
                print(f"BUCKET_ERROR:{bucket_name}:{str(e)}")
                sys.exit(1)
        
        print(f"BUCKETS_SUCCESS:{created_buckets}/{len(buckets)}")
        
        # 检查存储桶是否已有数据
        def bucket_has_objects(bucket_name, prefix=""):
            """检查存储桶是否已有对象（可选前缀）"""
            try:
                if prefix:
                    objects = list(client.list_objects(bucket_name, prefix=prefix, recursive=False))
                else:
                    objects = list(client.list_objects(bucket_name, recursive=False))
                return len(objects) > 0
            except:
                return False
        
        # 上传数据集（支持递归上传）
        total_upload_count = 0
        total_upload_success = 0
        
        def upload_file_recursive(bucket_name, local_path, object_prefix, root_dir):
            """递归上传文件"""
            upload_count = 0
            upload_success = 0
            
            if os.path.isfile(local_path):
                # 计算相对路径
                rel_path = os.path.relpath(local_path, root_dir)
                # 构建对象名称
                if object_prefix:
                    object_name = f"{object_prefix}/{rel_path}" if not object_prefix.endswith('/') else f"{object_prefix}{rel_path}"
                else:
                    object_name = rel_path
                
                # 统一路径分隔符为 /
                object_name = object_name.replace('\\', '/')
                
                try:
                    # 获取文件 MIME 类型
                    content_type, _ = mimetypes.guess_type(local_path)
                    if not content_type:
                        content_type = "application/octet-stream"
                    
                    # 上传文件
                    client.fput_object(
                        bucket_name,
                        object_name,
                        local_path,
                        content_type=content_type
                    )
                    print(f"UPLOAD_SUCCESS:{bucket_name}:{object_name}")
                    upload_success += 1
                except S3Error as e:
                    print(f"UPLOAD_ERROR:{bucket_name}:{object_name}:{str(e)}")
                upload_count += 1
            elif os.path.isdir(local_path):
                # 递归处理子目录
                for item in os.listdir(local_path):
                    item_path = os.path.join(local_path, item)
                    sub_count, sub_success = upload_file_recursive(bucket_name, item_path, object_prefix, root_dir)
                    upload_count += sub_count
                    upload_success += sub_success
            
            return upload_count, upload_success
        
        for bucket_name, dataset_dir, object_prefix in upload_tasks:
            if dataset_dir and os.path.isdir(dataset_dir):
                # 检查存储桶是否已有数据（检查特定前缀）
                if bucket_has_objects(bucket_name, object_prefix):
                    print(f"UPLOAD_SKIP:{bucket_name}:存储桶已存在且已有数据（前缀: {object_prefix if object_prefix else '根目录'}），跳过上传")
                else:
                    upload_count, upload_success = upload_file_recursive(bucket_name, dataset_dir, object_prefix, dataset_dir)
                    
                    print(f"UPLOAD_RESULT:{bucket_name}:{upload_success}/{upload_count}")
                    total_upload_count += upload_count
                    total_upload_success += upload_success
            else:
                print(f"UPLOAD_SKIP:{bucket_name}:数据集目录不存在或无效: {dataset_dir}")
        
        if total_upload_count > 0:
            print(f"UPLOAD_TOTAL:{total_upload_success}/{total_upload_count}")
        
        print("INIT_SUCCESS")
        sys.exit(0)
        
    except Exception as e:
        print(f"INIT_ERROR:{str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    init_minio_buckets_and_upload()
PYTHON_SCRIPT
    echo "$script_file"
}

# 初始化 MinIO 存储桶和数据
init_minio_with_python() {
    local python_script=$(create_minio_init_script)
    local output_file=$(mktemp)
    
    # 检查 Python 和 minio 库
    if ! command -v python3 &> /dev/null; then
        print_error "Python3 未安装，无法初始化 MinIO"
        rm -f "$python_script" "$output_file"
        return 1
    fi
    
    # 检查 minio 库是否安装
    if ! python3 -c "import minio" 2>/dev/null; then
        print_info "正在配置 pip 以允许安装系统包..."
        # 配置 pip 允许安装系统包，避免某些系统上的权限错误
        python3 -m pip config set global.break-system-packages true > /dev/null 2>&1 || true
        
        print_info "正在安装 minio Python 库..."
        pip3 install minio > /dev/null 2>&1 || {
            print_error "无法安装 minio Python 库，请手动安装: pip3 install minio"
            rm -f "$python_script" "$output_file"
            return 1
        }
    fi
    
    # 执行 Python 脚本，传递所有参数（只给所有者添加执行权限，避免需要 root 权限）
    chmod u+x "$python_script"
    python3 "$python_script" "$@" > "$output_file" 2>&1
    local exit_code=$?
    
    # 解析输出
    local buckets_created=0
    local buckets_total=0
    local upload_success=0
    local upload_total=0
    
    while IFS= read -r line || [ -n "$line" ]; do
        if [[ $line == BUCKET_EXISTS:* ]]; then
            local bucket_name="${line#BUCKET_EXISTS:}"
            print_info "存储桶 $bucket_name 已存在，跳过创建"
        elif [[ $line == BUCKET_CREATED:* ]]; then
            local bucket_name="${line#BUCKET_CREATED:}"
            print_success "存储桶 $bucket_name 创建成功"
            buckets_created=$((buckets_created + 1))
        elif [[ $line == BUCKET_ERROR:* ]]; then
            local error="${line#BUCKET_ERROR:}"
            print_error "存储桶创建失败: $error"
        elif [[ $line == BUCKETS_SUCCESS:* ]]; then
            local result="${line#BUCKETS_SUCCESS:}"
            IFS='/' read -r created_count total_count <<< "$result"
            buckets_total=$total_count
            # 只在没有单独计算时使用汇总数据
            if [ $buckets_created -eq 0 ]; then
                buckets_created=$created_count
            fi
        elif [[ $line == UPLOAD_SUCCESS:* ]]; then
            local upload_info="${line#UPLOAD_SUCCESS:}"
            # 格式可能是 bucket:object_name 或 object_name
            if [[ $upload_info == *:* ]]; then
                local bucket_name="${upload_info%%:*}"
                local object_name="${upload_info#*:}"
                print_info "文件上传成功 [$bucket_name]: $object_name"
            else
                print_info "文件上传成功: $upload_info"
            fi
            upload_success=$((upload_success + 1))
        elif [[ $line == UPLOAD_ERROR:* ]]; then
            local error_info="${line#UPLOAD_ERROR:}"
            # 格式可能是 bucket:object_name:error 或 object_name:error
            if [[ $error_info == *:*:* ]]; then
                local parts=(${error_info//:/ })
                local bucket_name="${parts[0]}"
                local object_name="${parts[1]}"
                local error_msg="${error_info#${bucket_name}:${object_name}:}"
                print_warning "文件上传失败 [$bucket_name]: $object_name - $error_msg"
            else
                print_warning "文件上传失败: $error_info"
            fi
        elif [[ $line == UPLOAD_RESULT:* ]]; then
            local result="${line#UPLOAD_RESULT:}"
            # 格式可能是 bucket:success/total 或 success/total
            if [[ $result == *:* ]]; then
                local bucket_result="${result#*:}"
                IFS='/' read -r success_count total_count <<< "$bucket_result"
                upload_total=$((upload_total + total_count))
                upload_success=$((upload_success + success_count))
            else
                IFS='/' read -r success_count total_count <<< "$result"
                upload_total=$total_count
                if [ $upload_success -eq 0 ]; then
                    upload_success=$success_count
                fi
            fi
        elif [[ $line == UPLOAD_TOTAL:* ]]; then
            local result="${line#UPLOAD_TOTAL:}"
            IFS='/' read -r success_count total_count <<< "$result"
            upload_total=$total_count
            upload_success=$success_count
        elif [[ $line == UPLOAD_SKIP:* ]]; then
            local reason="${line#UPLOAD_SKIP:}"
            print_warning "跳过上传: $reason"
        elif [[ $line == INIT_ERROR:* ]]; then
            local error="${line#INIT_ERROR:}"
            print_error "MinIO 初始化失败: $error"
        fi
    done < "$output_file"
    
    # 清理临时文件
    rm -f "$python_script" "$output_file"
    
    if [ $exit_code -eq 0 ]; then
        if [ $buckets_total -gt 0 ]; then
            print_info "存储桶创建: ${GREEN}$buckets_created${NC} / $buckets_total"
        fi
        if [ $upload_total -gt 0 ]; then
            print_info "文件上传: ${GREEN}$upload_success${NC} / $upload_total"
        fi
        return 0
    else
        return 1
    fi
}

# 初始化 MinIO 存储桶和数据
init_minio() {
    print_section "初始化 MinIO 存储桶和数据"
    
    # 等待 MinIO 就绪
    if ! wait_for_minio; then
        print_error "MinIO 未就绪，无法初始化存储桶"
        return 1
    fi
    
    # MinIO 数据源目录
    local minio_base_dir="${SCRIPT_DIR}/../minio"
    
    # 定义存储桶和目录映射关系
    # 格式: "bucket_name:relative_path:object_prefix"
    # relative_path 相对于 minio_base_dir
    # object_prefix 是上传到存储桶时的对象前缀（可选）
    local bucket_mappings=(
        # 格式: "bucket_name:relative_path:object_prefix"
        # dataset/3 目录的内容上传到 dataset 存储桶，对象路径前缀为 "3"
        # 例如: dataset/3/xxx.jpg -> dataset 存储桶中的 3/xxx.jpg
        "dataset:dataset/3:3"
        # 其他目录直接上传到对应的存储桶，保持原有目录结构
        "datasets:datasets:"
        "export-bucket:export-bucket:"
        "inference-inputs:inference-inputs:"
        "inference-results:inference-results:"
        "models:models:"
        "snap-space:snap-space:"
        # alert-images 存储桶用于存储告警图片（不需要上传初始数据）
    )
    
    # 构建上传任务参数
    local upload_args=()
    
    for mapping in "${bucket_mappings[@]}"; do
        IFS=':' read -r bucket_name relative_path object_prefix <<< "$mapping"
        
        # 构建完整目录路径
        local full_dir_path="${minio_base_dir}/${relative_path}"
        
        # 检查目录是否存在
        if [ -d "$full_dir_path" ]; then
            # 如果 object_prefix 为空，则使用空字符串
            if [ -z "$object_prefix" ]; then
                upload_args+=("${bucket_name}:${full_dir_path}:")
            else
                upload_args+=("${bucket_name}:${full_dir_path}:${object_prefix}")
            fi
            print_info "找到目录: $full_dir_path -> 存储桶: $bucket_name${object_prefix:+ (前缀: $object_prefix)}"
        else
            print_warning "目录不存在，跳过: $full_dir_path"
        fi
    done
    
    # 使用 Python 脚本初始化 MinIO
    local init_result=0
    if [ ${#upload_args[@]} -gt 0 ]; then
        if init_minio_with_python "${upload_args[@]}"; then
            print_success "MinIO 初始化完成！"
            init_result=0
        else
            print_warning "MinIO 初始化可能存在问题"
            init_result=1
        fi
    else
        print_warning "没有可用的数据集目录，跳过文件上传"
        # 仍然需要创建 bucket
        if init_minio_with_python; then
            print_success "MinIO 存储桶创建完成！"
            init_result=0
        else
            init_result=1
        fi
    fi
    
    # 如果初始化成功，提示用户登录 MinIO 管理平台
    if [ $init_result -eq 0 ]; then
        echo ""
        print_section "MinIO 管理平台登录提示"
        echo ""
        print_warning "重要提示：为了确保图像数据能够正常显示，请登录一次 MinIO 管理平台"
        print_info "  访问地址: http://localhost:9001"
        print_info "  用户名: minioadmin"
        print_info "  密码: basiclab@iot975248395"
        echo ""
        print_info "登录后，系统会自动完成必要的初始化配置，图像数据才能正常显示"
        echo ""
        
        while true; do
            echo -ne "${YELLOW}[提示]${NC} 是否已经登录过 MinIO 管理平台？(y/N): "
            read -r response
            case "$response" in
                [yY][eE][sS]|[yY])
                    print_success "确认已登录 MinIO 管理平台，继续执行..."
                    break
                    ;;
                [nN][oO]|[nN]|"")
                    print_warning "建议稍后登录 MinIO 管理平台以确保图像数据正常显示"
                    print_info "您可以稍后访问: http://localhost:9001"
                    break
                    ;;
                *)
                    print_warning "请输入 y 或 N"
                    ;;
            esac
        done
        echo ""
    fi
    
    return $init_result
}

# 初始化数据库
init_databases() {
    print_section "初始化数据库"
    
    # 等待 PostgreSQL 就绪
    if ! wait_for_postgresql; then
        print_error "PostgreSQL 未就绪，无法初始化数据库"
        return 1
    fi
    
    # 等待 Nacos 就绪
    if ! wait_for_nacos; then
        print_warning "Nacos 未就绪，将跳过 Nacos 密码重置确认步骤"
    fi
    
    # 定义数据库和 SQL 文件映射
    # SQL 文件路径：相对于脚本目录的上一级目录的 postgresql 目录
    local sql_dir="$(cd "${SCRIPT_DIR}/../postgresql" && pwd)"
    declare -A DB_SQL_MAP
    DB_SQL_MAP["iot-ai20"]="${sql_dir}/iot-ai10.sql"
    DB_SQL_MAP["iot-device20"]="${sql_dir}/iot-device10.sql"
    DB_SQL_MAP["iot-video20"]="${sql_dir}/iot-video10.sql"
    DB_SQL_MAP["ruoyi-vue-pro20"]="${sql_dir}/ruoyi-vue-pro10.sql"
    DB_SQL_MAP["iot-message20"]="${sql_dir}/iot-message10.sql"
    
    local success_count=0
    local total_count=${#DB_SQL_MAP[@]}
    
    # 创建数据库并执行 SQL 脚本
    for db_name in "${!DB_SQL_MAP[@]}"; do
        local sql_file="${DB_SQL_MAP[$db_name]}"
        
        if create_database "$db_name"; then
            # 检查数据库是否已初始化
            if check_database_initialized "$db_name"; then
                print_info "数据库 $db_name 已存在且已初始化，跳过 SQL 脚本执行"
                success_count=$((success_count + 1))
            else
                if execute_sql_script "$db_name" "$sql_file"; then
                    success_count=$((success_count + 1))
                fi
            fi
        fi
        echo ""
    done
    
    # 等待用户手动配置 Nacos 密码
    echo ""
    if wait_for_nacos; then
        print_section "Nacos 密码配置确认"
        echo ""
        print_info "请手动登录 Nacos 管理界面配置密码："
        print_info "  访问地址: http://localhost:8848/nacos"
        print_info "  用户名: nacos"
        echo ""
        print_warning "${RED}重要提示：${NC}新版本 Nacos 初始页面需要设置密码，请将密码配置为："
        print_warning "${YELLOW}basiclab@iot78475418754${NC}"
        echo ""
        print_warning "请确保已经完成密码配置，然后继续..."
        echo ""
        
        while true; do
            echo -ne "${YELLOW}[提示]${NC} 是否已经完成 Nacos 密码配置（密码必须为: basiclab@iot78475418754）？(y/N): "
            read -r response
            case "$response" in
                [yY][eE][sS]|[yY])
                    print_success "确认已配置 Nacos 密码，继续执行..."
                    break
                    ;;
                [nN][oO]|[nN]|"")
                    print_error "请先完成 Nacos 密码配置后再继续"
                    print_info "您可以："
                    print_info "  1. 访问 http://localhost:8848/nacos 进行密码配置"
                    print_info "  2. 密码必须设置为: basiclab@iot78475418754"
                    print_info "  3. 配置完成后重新运行此脚本"
                    exit 1
                    ;;
                *)
                    print_warning "请输入 y 或 N"
                    ;;
            esac
        done
    fi
    
    echo ""
    print_section "数据库初始化结果"
    echo "成功: ${GREEN}$success_count${NC} / $total_count"
    
    if [ $success_count -eq $total_count ]; then
        print_success "所有数据库初始化完成！"
        return 0
    else
        print_warning "部分数据库初始化失败"
        return 1
    fi
}

# 检查并拉取缺失的镜像
check_and_pull_images() {
    print_info "检查所需镜像是否存在..."
    
    # 获取 docker-compose.yml 中定义的所有服务
    local services=$($COMPOSE_CMD -f "$COMPOSE_FILE" config --services 2>/dev/null || echo "")
    
    if [ -z "$services" ]; then
        print_warning "无法获取服务列表，将直接启动服务（会自动拉取缺失镜像）"
        return 0
    fi
    
    local missing_images=0
    local existing_images=0
    local images_to_check=()
    
    # 从 docker-compose 配置中提取所有镜像信息
    local compose_config=$($COMPOSE_CMD -f "$COMPOSE_FILE" config 2>/dev/null || echo "")
    
    if [ -z "$compose_config" ]; then
        print_warning "无法读取 docker-compose 配置，将直接启动服务"
        return 0
    fi
    
    # 提取所有镜像名称（处理多种格式）
    while IFS= read -r line; do
        # 匹配 image: 行，支持多种格式
        if echo "$line" | grep -qE "^\s*image:"; then
            local image=$(echo "$line" | sed -E 's/^\s*image:\s*//' | sed -E "s/^['\"]//" | sed -E "s/['\"]$//" | tr -d ' ')
            if [ -n "$image" ] && [[ ! " ${images_to_check[@]} " =~ " ${image} " ]]; then
                images_to_check+=("$image")
            fi
        fi
    done <<< "$compose_config"
    
    # 检查每个镜像是否存在
    for image in "${images_to_check[@]}"; do
        if docker image inspect "$image" &> /dev/null; then
            print_info "镜像已存在: $image"
            existing_images=$((existing_images + 1))
        else
            print_warning "镜像不存在: $image"
            missing_images=$((missing_images + 1))
        fi
    done
    
    # 如果有缺失的镜像，才执行拉取
    if [ $missing_images -gt 0 ]; then
        print_info "发现 $missing_images 个缺失镜像，开始拉取..."
        print_info "已存在 $existing_images 个镜像，跳过拉取"
        $COMPOSE_CMD -f "$COMPOSE_FILE" pull 2>&1 | tee -a "$LOG_FILE"
        print_success "镜像拉取完成"
    else
        if [ ${#images_to_check[@]} -gt 0 ]; then
            print_success "所有所需镜像已存在（${#images_to_check[@]} 个），跳过拉取步骤（节省时间）"
        else
            print_info "未检测到需要拉取的镜像，将直接启动服务"
        fi
    fi
}

# 从 docker-compose.yml 提取所有端口映射
extract_ports_from_compose() {
    local service_name=$1
    local ports=()
    
    # 使用 docker-compose config 获取端口映射
    local port_mappings=$($COMPOSE_CMD -f "$COMPOSE_FILE" config 2>/dev/null | grep -A 20 "^  ${service_name}:" | grep -E "^\s+- \"[0-9]+:" | sed 's/.*"\([0-9]*\):.*/\1/' || echo "")
    
    if [ -n "$port_mappings" ]; then
        while IFS= read -r port; do
            if [ -n "$port" ]; then
                ports+=("$port")
            fi
        done <<< "$port_mappings"
    fi
    
    # 如果没有找到，使用默认端口
    if [ ${#ports[@]} -eq 0 ]; then
        case "$service_name" in
            "TDengine")
                ports=("6030" "6041" "6060" "6043" "6044" "6045" "6046" "6047" "6048" "6049")
                ;;
            "Redis")
                ports=("6379")
                ;;
            "PostgresSQL")
                ports=("5432")
                ;;
            "Nacos")
                ports=("8848" "9848" "9849")
                ;;
            "Kafka")
                ports=("9092" "9093")
                ;;
            "MinIO")
                ports=("9000" "9001")
                ;;
            "SRS")
                ports=("1935" "1985" "8080" "8000")
                ;;
            "NodeRED")
                ports=("1880")
                ;;
            "EMQX")
                ports=("1883" "8883" "8083" "8084" "18083")
                ;;
        esac
    fi
    
    echo "${ports[@]}"
}

# 检查端口占用并清理
check_and_clean_ports() {
    print_info "检查端口占用情况..."
    local has_conflict=0
    local conflict_ports=()
    local conflict_containers=()
    
    # 先执行 docker-compose down 清理所有残留容器和端口绑定
    print_info "清理 docker-compose 管理的容器和端口绑定..."
    $COMPOSE_CMD -f "$COMPOSE_FILE" down 2>/dev/null || true
    sleep 2
    
    # 强制清理所有可能占用端口的容器（包括停止状态的）
    print_info "清理所有可能占用端口的残留容器..."
    for service in "${MIDDLEWARE_SERVICES[@]}"; do
        local container_name=""
        case "$service" in
            "Nacos") container_name="nacos-server" ;;
            "PostgresSQL") container_name="postgres-server" ;;
            "TDengine") container_name="tdengine-server" ;;
            "Redis") container_name="redis-server" ;;
            "Kafka") container_name="kafka-server" ;;
            "MinIO") container_name="minio-server" ;;
            "SRS") container_name="srs-server" ;;
            "NodeRED") container_name="nodered-server" ;;
            "EMQX") container_name="emqx-server" ;;
        esac
        
        if [ -n "$container_name" ]; then
            # 查找所有状态（运行中、已停止）的容器
            local existing_containers=$(docker ps -a --filter "name=^${container_name}$" --format "{{.ID}}" 2>/dev/null || echo "")
            if [ -n "$existing_containers" ]; then
                echo "$existing_containers" | while read -r container_id; do
                    if [ -n "$container_id" ]; then
                        print_info "强制清理残留容器: $container_name ($container_id)"
                        docker stop -t 0 "$container_id" 2>/dev/null || true
                        docker rm -f "$container_id" 2>/dev/null || true
                    fi
                done
            fi
        fi
    done
    
    # 等待端口释放（Docker 需要时间释放端口绑定）
    print_info "等待端口释放（最多等待 10 秒）..."
    local wait_count=0
    local max_wait=10
    while [ $wait_count -lt $max_wait ]; do
        local ports_still_in_use=0
        for service in "${MIDDLEWARE_SERVICES[@]}"; do
            local port="${MIDDLEWARE_PORTS[$service]}"
            if [ -z "$port" ]; then
                continue
            fi
            
            # 检查是否还有 Docker 容器占用端口
            local docker_using_port=$(docker ps --format "{{.Ports}}" 2>/dev/null | grep -E ":$port->|0\.0\.0\.0:$port|:::$port" || echo "")
            if [ -n "$docker_using_port" ]; then
                ports_still_in_use=1
                break
            fi
        done
        
        if [ $ports_still_in_use -eq 0 ]; then
            break
        fi
        
        wait_count=$((wait_count + 1))
        sleep 1
        echo -n "."
    done
    echo ""
    
    if [ $wait_count -ge $max_wait ]; then
        print_warning "等待端口释放超时，继续检查..."
    else
        print_success "端口已释放"
    fi
    
    sleep 1
    
    # 检查所有中间件端口（包括所有映射的端口）
    for service in "${MIDDLEWARE_SERVICES[@]}"; do
        # 获取该服务的所有端口映射
        local service_ports=($(extract_ports_from_compose "$service"))
        
        if [ ${#service_ports[@]} -eq 0 ]; then
            # 如果没有找到，使用默认主端口
            local port="${MIDDLEWARE_PORTS[$service]}"
            if [ -z "$port" ]; then
                continue
            fi
            service_ports=("$port")
        fi
        
        # 检查该服务的所有端口
        for port in "${service_ports[@]}"; do
            if [ -z "$port" ]; then
                continue
            fi
            
            # 检查端口是否被占用（使用多种方法）
            local port_in_use=0
            local port_user=""
            
            # 方法1: 使用 ss 命令（最可靠）
            if command -v ss &> /dev/null; then
                if ss -tlnp 2>/dev/null | grep -qE ":$port[[:space:]]|:$port$"; then
                    port_in_use=1
                    port_user=$(ss -tlnp 2>/dev/null | grep -E ":$port[[:space:]]|:$port$" | head -1)
                fi
            # 方法2: 使用 netstat 命令
            elif command -v netstat &> /dev/null; then
                if netstat -tlnp 2>/dev/null | grep -qE ":$port[[:space:]]|:$port$"; then
                    port_in_use=1
                    port_user=$(netstat -tlnp 2>/dev/null | grep -E ":$port[[:space:]]|:$port$" | head -1)
                fi
            # 方法3: 使用 lsof 命令
            elif command -v lsof &> /dev/null; then
                if lsof -i :$port 2>/dev/null | grep -q LISTEN; then
                    port_in_use=1
                    port_user=$(lsof -i :$port 2>/dev/null | grep LISTEN | head -1)
                fi
            # 方法4: 使用 /proc/net/tcp (Linux)
            elif [ -f /proc/net/tcp ]; then
                local hex_port=$(printf "%04X" $port | tr '[:lower:]' '[:upper:]')
                if grep -qE ":$hex_port[[:space:]]|:$hex_port$" /proc/net/tcp 2>/dev/null; then
                    port_in_use=1
                fi
            fi
            
            # 方法5: 通过 Docker 直接检查端口映射
            local docker_port_check=$(docker ps --format "{{.ID}}\t{{.Ports}}" 2>/dev/null | grep -E ":$port->|0\.0\.0\.0:$port|:::$port" || echo "")
            if [ -n "$docker_port_check" ]; then
                port_in_use=1
                if [ -z "$port_user" ]; then
                    port_user="Docker容器: $docker_port_check"
                fi
            fi
            
            if [ $port_in_use -eq 1 ]; then
                # 检查是否是 Docker 容器占用的
                local container_id=""
                local container_name=""
                local is_docker_process=0
                
                # 通过 docker ps 查找占用端口的容器（多种格式匹配）
                while IFS= read -r line; do
                    if echo "$line" | grep -qE ":$port->|0\.0\.0\.0:$port|:::$port"; then
                        container_id=$(echo "$line" | awk '{print $1}')
                        container_name=$(echo "$line" | awk '{print $NF}')
                        is_docker_process=1
                        break
                    fi
                done < <(docker ps --format "{{.ID}}\t{{.Ports}}\t{{.Names}}" 2>/dev/null || true)
                
                # 如果没找到，尝试通过容器名称查找
                if [ -z "$container_id" ]; then
                    case "$service" in
                        "TDengine") 
                            container_id=$(docker ps --filter "name=tdengine" --format "{{.ID}}" 2>/dev/null | head -1)
                            container_name=$(docker ps --filter "name=tdengine" --format "{{.Names}}" 2>/dev/null | head -1)
                            if [ -n "$container_id" ]; then
                                is_docker_process=1
                            fi
                            ;;
                        "Redis")
                            container_id=$(docker ps --filter "name=redis" --format "{{.ID}}" 2>/dev/null | head -1)
                            container_name=$(docker ps --filter "name=redis" --format "{{.Names}}" 2>/dev/null | head -1)
                            if [ -n "$container_id" ]; then
                                is_docker_process=1
                            fi
                            ;;
                    esac
                fi
                
                if [ $is_docker_process -eq 1 ] && [ -n "$container_id" ]; then
                    # 检查是否是当前 compose 项目的容器
                    local compose_project=$(docker inspect "$container_id" --format '{{index .Config.Labels "com.docker.compose.project"}}' 2>/dev/null || echo "")
                    local compose_service=$(docker inspect "$container_id" --format '{{index .Config.Labels "com.docker.compose.service"}}' 2>/dev/null || echo "")
                    
                    # 如果不是当前项目的容器，或者容器名称不匹配，则认为是冲突
                    if [ -z "$compose_project" ] || [ "$compose_service" != "$service" ]; then
                        print_warning "端口 $port ($service) 被 Docker 容器 $container_name ($container_id) 占用"
                        conflict_ports+=("$port")
                        conflict_containers+=("$container_id")
                        has_conflict=1
                    fi
                else
                    # 非 Docker 进程占用（宿主机上的进程）
                    print_warning "端口 $port ($service) 被宿主机进程占用（非 Docker 容器）"
                    print_info "占用信息: $port_user"
                    
                    # 尝试识别进程信息
                    local process_info=""
                    if command -v lsof &> /dev/null; then
                        process_info=$(lsof -i :$port 2>/dev/null | grep LISTEN | head -1 || echo "")
                    elif command -v ss &> /dev/null; then
                        process_info=$(ss -tlnp 2>/dev/null | grep ":$port " | head -1 || echo "")
                    fi
                    
                    if [ -n "$process_info" ]; then
                        print_info "进程详情: $process_info"
                    fi
                    
                    conflict_ports+=("$port")
                    has_conflict=1
                fi
            fi
        done
    done
    
    # 再次验证所有端口（清理后）
    if [ $has_conflict -eq 0 ]; then
        print_info "二次验证端口状态..."
        sleep 1
        for service in "${MIDDLEWARE_SERVICES[@]}"; do
            local port="${MIDDLEWARE_PORTS[$service]}"
            if [ -z "$port" ]; then
                continue
            fi
            
            if command -v ss &> /dev/null && ss -tlnp 2>/dev/null | grep -qE ":$port[[:space:]]|:$port$"; then
                print_warning "端口 $port ($service) 在清理后仍被占用"
                conflict_ports+=("$port")
                has_conflict=1
            fi
        done
    fi
    
    if [ $has_conflict -eq 1 ]; then
        echo ""
        print_warning "发现端口冲突！"
        print_warning "冲突端口: ${conflict_ports[*]}"
        echo ""
        
        # 检查是否有宿主机进程占用
        local has_host_process=0
        for port in "${conflict_ports[@]}"; do
            local docker_using=$(docker ps --format "{{.Ports}}" 2>/dev/null | grep -E ":$port->|0\.0\.0\.0:$port|:::$port" || echo "")
            if [ -z "$docker_using" ]; then
                # 检查是否是宿主机进程
                if command -v ss &> /dev/null && ss -tlnp 2>/dev/null | grep -qE ":$port[[:space:]]|:$port$"; then
                    has_host_process=1
                    break
                fi
            fi
        done
        
        if [ $has_host_process -eq 1 ]; then
            print_error "检测到宿主机进程占用端口，这可能导致容器启动失败！"
            echo ""
            echo "请选择操作："
            echo "  1. 尝试停止宿主机上的 Redis/TDengine 服务（如果存在）"
            echo "  2. 手动处理端口冲突（推荐：停止占用端口的服务或修改 docker-compose.yml 端口映射）"
            echo "  3. 继续启动（可能会失败）"
            echo ""
            read -p "请输入选项 (1/2/3): " choice
        else
            echo "请选择操作："
            echo "  1. 自动强制清理所有冲突容器和进程（推荐）"
            echo "  2. 手动处理端口冲突"
            echo "  3. 继续启动（可能失败）"
            echo ""
            read -p "请输入选项 (1/2/3): " choice
        fi
        
        case "$choice" in
            1)
                if [ $has_host_process -eq 1 ]; then
                    # 尝试停止宿主机服务
                    print_info "尝试停止宿主机上的服务..."
                    
                    for port in "${conflict_ports[@]}"; do
                        # 检查是否是 Redis 端口
                        if [ "$port" = "6379" ]; then
                            print_info "检测到 Redis 端口 6379 被占用，尝试停止系统 Redis 服务..."
                            # 尝试停止常见的 Redis 服务
                            if systemctl is-active --quiet redis 2>/dev/null || systemctl is-active --quiet redis-server 2>/dev/null; then
                                print_info "停止 Redis 系统服务..."
                                sudo systemctl stop redis 2>/dev/null || sudo systemctl stop redis-server 2>/dev/null || true
                                sleep 2
                            fi
                            
                            # 尝试通过进程名查找并停止
                            local redis_pid=$(pgrep -f "redis-server" 2>/dev/null | head -1 || echo "")
                            if [ -n "$redis_pid" ]; then
                                print_info "发现 Redis 进程 (PID: $redis_pid)，尝试停止..."
                                sudo kill "$redis_pid" 2>/dev/null || true
                                sleep 2
                            fi
                        fi
                        
                        # 检查是否是 TDengine 端口（6030, 6041, 6060, 6043-6049）
                        if [[ "$port" =~ ^60[34][0-9]$ ]] || [ "$port" = "6030" ] || [ "$port" = "6041" ] || [ "$port" = "6060" ]; then
                            print_info "检测到 TDengine 端口 $port 被占用，尝试彻底停止所有 TDengine 相关服务..."
                            
                            # 1. 停止 systemd 服务（如果存在）
                            if systemctl is-active --quiet taosd 2>/dev/null; then
                                print_info "停止 TDengine systemd 服务..."
                                sudo systemctl stop taosd 2>/dev/null || true
                                sudo systemctl disable taosd 2>/dev/null || true
                                sleep 2
                            fi
                            
                            # 2. 停止所有 TDengine 相关进程（包括容器中的）
                            print_info "查找并停止所有 TDengine 相关进程..."
                            
                            # 查找所有 taos 相关进程（包括 taosd, taosadapter, taoskeeper, taos-explorer, udfd）
                            local taos_pids=$(pgrep -f "taos" 2>/dev/null || echo "")
                            if [ -n "$taos_pids" ]; then
                                echo "$taos_pids" | while read -r pid; do
                                    if [ -n "$pid" ]; then
                                        local proc_name=$(ps -p "$pid" -o comm= 2>/dev/null || echo "")
                                        print_info "发现 TDengine 进程: $proc_name (PID: $pid)，尝试停止..."
                                        sudo kill -TERM "$pid" 2>/dev/null || true
                                        sleep 1
                                        # 如果进程仍在运行，强制杀死
                                        if kill -0 "$pid" 2>/dev/null; then
                                            print_info "强制停止进程 PID: $pid"
                                            sudo kill -KILL "$pid" 2>/dev/null || true
                                        fi
                                    fi
                                done
                                sleep 2
                            fi
                            
                            # 3. 停止所有包含 taos 的 Docker 容器
                            print_info "查找并停止所有 TDengine 相关 Docker 容器..."
                            local taos_containers=$(docker ps -a --filter "name=taos" --format "{{.ID}}" 2>/dev/null || echo "")
                            if [ -n "$taos_containers" ]; then
                                echo "$taos_containers" | while read -r cid; do
                                    if [ -n "$cid" ]; then
                                        local container_name=$(docker ps -a --filter "id=$cid" --format "{{.Names}}" 2>/dev/null || echo "")
                                        print_info "停止 TDengine 容器: $container_name ($cid)"
                                        docker stop -t 0 "$cid" 2>/dev/null || true
                                        docker rm -f "$cid" 2>/dev/null || true
                                    fi
                                done
                                sleep 2
                            fi
                            
                            # 4. 再次检查并强制清理残留进程
                            sleep 2
                            local remaining_pids=$(pgrep -f "taos" 2>/dev/null || echo "")
                            if [ -n "$remaining_pids" ]; then
                                print_warning "仍有 TDengine 进程残留，强制清理..."
                                echo "$remaining_pids" | while read -r pid; do
                                    if [ -n "$pid" ]; then
                                        sudo kill -KILL "$pid" 2>/dev/null || true
                                    fi
                                done
                                sleep 1
                            fi
                            
                            # 5. 检查端口是否已释放
                            sleep 2
                            if command -v ss &> /dev/null && ss -tlnp 2>/dev/null | grep -qE ":$port[[:space:]]|:$port$"; then
                                print_warning "端口 $port 仍被占用，可能不是 TDengine 进程"
                                print_info "占用端口的进程信息:"
                                ss -tlnp 2>/dev/null | grep -E ":$port[[:space:]]|:$port$" || true
                            else
                                print_success "TDengine 端口 $port 已释放"
                            fi
                        fi
                    done
                    
                    # 等待端口释放
                    print_info "等待端口释放..."
                    sleep 3
                    
                    # 再次检查端口
                    local still_occupied=0
                    for port in "${conflict_ports[@]}"; do
                        if command -v ss &> /dev/null && ss -tlnp 2>/dev/null | grep -qE ":$port[[:space:]]|:$port$"; then
                            print_warning "端口 $port 仍被占用"
                            still_occupied=1
                        fi
                    done
                    
                    if [ $still_occupied -eq 1 ]; then
                        print_error "无法自动释放端口，请手动处理"
                        print_info "检查命令: sudo lsof -i :端口号 或 sudo ss -tlnp | grep 端口号"
                        print_info "停止服务命令示例:"
                        print_info "  sudo systemctl stop redis  # Redis"
                        print_info "  sudo systemctl stop taosd  # TDengine"
                        print_info "或修改 docker-compose.yml 中的端口映射（如 6379 改为 6380）"
                        echo ""
                        read -p "是否继续启动（可能会失败）？(y/N): " continue_choice
                        if [ "$continue_choice" != "y" ] && [ "$continue_choice" != "Y" ]; then
                            print_info "已取消启动"
                            exit 1
                        fi
                    else
                        print_success "端口已释放"
                    fi
                else
                    # 清理 Docker 容器
                    print_info "正在强制清理冲突的容器..."
                    for container_id in "${conflict_containers[@]}"; do
                        if [ -n "$container_id" ]; then
                            print_info "强制停止并删除容器: $container_id"
                            docker stop -t 0 "$container_id" 2>/dev/null || true
                            docker rm -f "$container_id" 2>/dev/null || true
                        fi
                    done
                    
                    # 清理所有相关容器（按名称）
                    for port in "${conflict_ports[@]}"; do
                        for service in "${MIDDLEWARE_SERVICES[@]}"; do
                            if [ "${MIDDLEWARE_PORTS[$service]}" = "$port" ]; then
                                local container_name=""
                                case "$service" in
                                    "TDengine") container_name="tdengine-server" ;;
                                    "Redis") container_name="redis-server" ;;
                                    "PostgresSQL") container_name="postgres-server" ;;
                                    "Nacos") container_name="nacos-server" ;;
                                    "Kafka") container_name="kafka-server" ;;
                                    "MinIO") container_name="minio-server" ;;
                                    "SRS") container_name="srs-server" ;;
                                    "NodeRED") container_name="nodered-server" ;;
                                    "EMQX") container_name="emqx-server" ;;
                                esac
                                
                                if [ -n "$container_name" ]; then
                                    docker ps -a --filter "name=^${container_name}$" --format "{{.ID}}" 2>/dev/null | while read -r cid; do
                                        if [ -n "$cid" ]; then
                                            print_info "清理容器: $container_name ($cid)"
                                            docker stop -t 0 "$cid" 2>/dev/null || true
                                            docker rm -f "$cid" 2>/dev/null || true
                                        fi
                                    done
                                fi
                                break
                            fi
                        done
                    done
                fi
                
                sleep 3
                print_success "容器清理完成"
                
                # 等待端口释放
                print_info "等待端口释放（最多等待 5 秒）..."
                local wait_count=0
                local max_wait=5
                while [ $wait_count -lt $max_wait ]; do
                    local ports_still_in_use=0
                    for port in "${conflict_ports[@]}"; do
                        # 检查是否还有 Docker 容器占用
                        local docker_using=$(docker ps --format "{{.Ports}}" 2>/dev/null | grep -E ":$port->|0\.0\.0\.0:$port|:::$port" || echo "")
                        if [ -n "$docker_using" ]; then
                            ports_still_in_use=1
                            break
                        fi
                    done
                    
                    if [ $ports_still_in_use -eq 0 ]; then
                        break
                    fi
                    
                    wait_count=$((wait_count + 1))
                    sleep 1
                    echo -n "."
                done
                echo ""
                
                # 再次检查端口（区分 Docker 和宿主机进程）
                print_info "再次检查端口状态..."
                local still_conflict=0
                local host_process_conflict=0
                for port in "${conflict_ports[@]}"; do
                    # 先检查是否是 Docker 容器占用
                    local docker_using=$(docker ps --format "{{.ID}}\t{{.Names}}\t{{.Ports}}" 2>/dev/null | grep -E ":$port->|0\.0\.0\.0:$port|:::$port" || echo "")
                    
                    if [ -n "$docker_using" ]; then
                        print_error "端口 $port 仍被 Docker 容器占用:"
                        echo "$docker_using" | while read -r line; do
                            print_info "  $line"
                        done
                        still_conflict=1
                    elif command -v ss &> /dev/null && ss -tlnp 2>/dev/null | grep -qE ":$port[[:space:]]|:$port$"; then
                        # 检查是否是宿主机进程占用
                        local host_process=$(ss -tlnp 2>/dev/null | grep -E ":$port[[:space:]]|:$port$" | head -1 || echo "")
                        if [ -n "$host_process" ]; then
                            print_error "端口 $port 被宿主机进程占用（非 Docker）:"
                            print_info "  $host_process"
                            print_info "  这可能是系统服务，需要手动停止或修改配置"
                            host_process_conflict=1
                        fi
                    fi
                done
                
                if [ $still_conflict -eq 1 ]; then
                    print_error "部分端口仍被 Docker 容器占用，启动可能会失败"
                    print_info "建议手动检查并清理: docker ps | grep 端口号"
                elif [ $host_process_conflict -eq 1 ]; then
                    print_error "部分端口被宿主机进程占用，启动可能会失败"
                    print_info "建议手动检查: sudo lsof -i :端口号 或 sudo ss -tlnp | grep 端口号"
                    print_info "如果是系统服务，可能需要停止服务或修改 docker-compose.yml 中的端口映射"
                fi
                ;;
            2)
                print_info "请手动处理端口冲突后重新运行此脚本"
                print_info "冲突端口: ${conflict_ports[*]}"
                print_info "检查命令: sudo lsof -i :端口号 或 sudo ss -tlnp | grep 端口号"
                exit 1
                ;;
            3)
                print_warning "继续启动，可能会失败..."
                ;;
            *)
                print_error "无效选项"
                exit 1
                ;;
        esac
    else
        print_success "所有端口检查通过"
    fi
}

# 清理残留的容器（与 compose 项目相关的）
cleanup_stale_containers() {
    print_info "检查并清理残留容器..."
    
    # 获取所有中间件容器名称
    local container_names=()
    for service in "${MIDDLEWARE_SERVICES[@]}"; do
        local container_name=$(docker-compose -f "$COMPOSE_FILE" ps -q "$service" 2>/dev/null || echo "")
        if [ -z "$container_name" ]; then
            # 尝试通过容器名称查找
            case "$service" in
                "Nacos") container_names+=("nacos-server") ;;
                "PostgresSQL") container_names+=("postgres-server") ;;
                "TDengine") container_names+=("tdengine-server") ;;
                "Redis") container_names+=("redis-server") ;;
                "Kafka") container_names+=("kafka-server") ;;
                "MinIO") container_names+=("minio-server") ;;
                "SRS") container_names+=("srs-server") ;;
                "NodeRED") container_names+=("nodered-server") ;;
                "EMQX") container_names+=("emqx-server") ;;
            esac
        fi
    done
    
    # 检查是否有停止的容器需要清理
    local stale_containers=$(docker ps -a --filter "status=exited" --format "{{.Names}}" 2>/dev/null | grep -E "(nacos-server|postgres-server|tdengine-server|redis-server|kafka-server|minio-server|srs-server|nodered-server|emqx-server)" || echo "")
    
    if [ -n "$stale_containers" ]; then
        print_info "发现残留的停止容器，正在清理..."
        echo "$stale_containers" | while read -r container; do
            print_info "删除残留容器: $container"
            docker rm "$container" 2>/dev/null || true
        done
        sleep 1
    fi
}

# 安装所有中间件
install_middleware() {
    print_section "开始安装所有中间件"
    
    # 配置 apt 国内源（在安装依赖之前）
    configure_apt_mirror
    
    # 配置 pip 镜像源
    configure_pip_mirror
    
    check_docker "$@"
    check_docker_compose
    
    # 检查并安装 nvidia-container-toolkit（在配置 Docker 镜像源之前）
    check_and_install_nvidia_container_toolkit
    
    # 配置 Docker 镜像源（需要在 nvidia-container-toolkit 安装之后）
    configure_docker_mirror
    check_compose_file
    create_network
    
    # 创建所有中间件的存储目录（如果不存在则创建新的）
    create_all_storage_directories
    
    # 确保关键目录的权限正确（这些函数会检查并设置权限）
    create_postgresql_directories
    create_redis_directories
    create_nodered_directories
    create_kafka_directories
    
    # 强制更新 SRS 配置文件（重新获取宿主机 IP）
    prepare_srs_config
    prepare_emqx_volumes
    
    # 检查并拉取缺失的镜像（如果镜像已存在则跳过拉取）
    echo ""
    check_and_pull_images
    
    # 清理残留容器
    cleanup_stale_containers
    
    # 检查端口占用
    check_and_clean_ports
    
    print_info "启动所有中间件服务..."
    if $COMPOSE_CMD -f "$COMPOSE_FILE" up -d 2>&1 | tee -a "$LOG_FILE"; then
        print_success "容器启动命令执行完成"
    else
        print_error "容器启动过程中出现错误"
    fi
    
    # 如果 SRS 容器已经在运行，重启它以重新加载配置文件
    if docker ps --filter "name=srs-server" --format "{{.Names}}" | grep -q "srs-server"; then
        print_info "检测到 SRS 容器正在运行，重启以重新加载配置文件..."
        docker restart srs-server 2>&1 | tee -a "$LOG_FILE" || true
        print_success "SRS 容器已重启，配置文件已重新加载"
    fi
    
    # 检查启动状态
    sleep 3
    print_info "检查容器启动状态..."
    local failed_containers=()
    for service in "${MIDDLEWARE_SERVICES[@]}"; do
        local container_name=""
        case "$service" in
            "Nacos") container_name="nacos-server" ;;
            "PostgresSQL") container_name="postgres-server" ;;
            "TDengine") container_name="tdengine-server" ;;
            "Redis") container_name="redis-server" ;;
            "Kafka") container_name="kafka-server" ;;
            "MinIO") container_name="minio-server" ;;
            "SRS") container_name="srs-server" ;;
            "NodeRED") container_name="nodered-server" ;;
            "EMQX") container_name="emqx-server" ;;
        esac
        
        if [ -n "$container_name" ]; then
            local container_status=$(docker ps -a --filter "name=^${container_name}$" --format "{{.Status}}" 2>/dev/null | head -1 || echo "")
            if [ -n "$container_status" ]; then
                if echo "$container_status" | grep -qE "Exited|Dead|Restarting"; then
                    print_warning "$service ($container_name) 容器状态异常: $container_status"
                    failed_containers+=("$service")
                fi
            fi
        fi
    done
    
    if [ ${#failed_containers[@]} -gt 0 ]; then
        echo ""
        print_error "以下容器启动失败: ${failed_containers[*]}"
        print_info "查看详细日志命令:"
        for service in "${failed_containers[@]}"; do
            case "$service" in
                "TDengine") print_info "  docker logs tdengine-server" ;;
                "Redis") print_info "  docker logs redis-server" ;;
                *) print_info "  docker-compose logs $service" ;;
            esac
        done
        echo ""
    fi
    
    print_success "中间件安装完成"
    echo ""
    print_info "等待服务启动..."
    sleep 10
    
    # 确保 PostgreSQL 密码正确（确保重启后密码正确）
    echo ""
    ensure_postgresql_password
    
    # 配置 PostgreSQL pg_hba.conf 允许从宿主机连接
    echo ""
    configure_postgresql_pg_hba
    
    # 配置 PostgreSQL max_connections（最大连接数）
    echo ""
    configure_postgresql_max_connections
    
    # 初始化数据库
    echo ""
    init_databases
    
    # 初始化 TDengine
    echo ""
    init_tdengine
    
    # 初始化 MinIO
    echo ""
    init_minio
}

# 启动所有中间件
start_middleware() {
    print_section "启动所有中间件"
    
    check_docker "$@"
    check_docker_compose
    check_compose_file
    create_network
    
    # 创建所有中间件的存储目录（如果不存在则创建新的）
    create_all_storage_directories
    
    # 确保关键目录的权限正确
    create_postgresql_directories
    create_redis_directories
    create_nodered_directories
    create_kafka_directories
    
    prepare_srs_config
    prepare_emqx_volumes
    
    # 清理残留容器
    cleanup_stale_containers
    
    # 检查端口占用
    check_and_clean_ports
    
    print_info "启动所有中间件服务..."
    $COMPOSE_CMD -f "$COMPOSE_FILE" up -d 2>&1 | tee -a "$LOG_FILE"
    
    print_success "所有中间件启动完成"
    echo ""
    print_info "等待服务就绪..."
    sleep 15
    
    # 确保 PostgreSQL 密码正确（确保重启后密码正确）
    echo ""
    ensure_postgresql_password
    
    # 配置 PostgreSQL pg_hba.conf 允许从宿主机连接
    echo ""
    configure_postgresql_pg_hba
    
    # 配置 PostgreSQL max_connections（最大连接数）
    echo ""
    configure_postgresql_max_connections
}

# 停止所有中间件
stop_middleware() {
    print_section "停止所有中间件"
    
    check_docker "$@"
    check_docker_compose
    check_compose_file
    
    print_info "停止所有中间件服务..."
    $COMPOSE_CMD -f "$COMPOSE_FILE" down 2>&1 | tee -a "$LOG_FILE"
    
    print_success "所有中间件已停止"
}

# 重启所有中间件
restart_middleware() {
    print_section "重启所有中间件"
    
    check_docker "$@"
    check_docker_compose
    check_compose_file
    create_network
    
    # 创建所有中间件的存储目录（如果不存在则创建新的）
    create_all_storage_directories
    
    # 确保关键目录的权限正确
    create_postgresql_directories
    create_redis_directories
    create_nodered_directories
    create_kafka_directories
    
    prepare_srs_config
    prepare_emqx_volumes
    
    print_info "重启所有中间件服务..."
    $COMPOSE_CMD -f "$COMPOSE_FILE" restart 2>&1 | tee -a "$LOG_FILE"
    
    print_success "所有中间件重启完成"
    echo ""
    print_info "等待服务就绪..."
    sleep 15
    
    # 确保 PostgreSQL 密码正确（确保重启后密码正确）
    echo ""
    ensure_postgresql_password
    
    # 配置 PostgreSQL pg_hba.conf 允许从宿主机连接
    echo ""
    configure_postgresql_pg_hba
    
    # 配置 PostgreSQL max_connections（最大连接数）
    echo ""
    configure_postgresql_max_connections
}

# 查看所有中间件状态
status_middleware() {
    print_section "所有中间件状态"
    
    check_docker "$@"
    check_docker_compose
    check_compose_file
    
    $COMPOSE_CMD -f "$COMPOSE_FILE" ps 2>&1 | tee -a "$LOG_FILE"
}

# 查看日志
view_logs() {
    local service=${1:-""}
    
    check_docker "$@"
    check_docker_compose
    check_compose_file
    
    if [ -z "$service" ]; then
        print_info "查看所有中间件日志..."
        $COMPOSE_CMD -f "$COMPOSE_FILE" logs --tail=100 2>&1 | tee -a "$LOG_FILE"
    else
        print_info "查看 $service 服务日志..."
        $COMPOSE_CMD -f "$COMPOSE_FILE" logs --tail=100 "$service" 2>&1 | tee -a "$LOG_FILE"
    fi
}

# 构建所有镜像
build_middleware() {
    print_section "构建所有中间件镜像"
    
    check_docker "$@"
    check_docker_compose
    check_compose_file
    
    print_info "构建所有中间件镜像..."
    $COMPOSE_CMD -f "$COMPOSE_FILE" build --no-cache 2>&1 | tee -a "$LOG_FILE"
    
    print_success "所有中间件镜像构建完成"
}

# 删除数据库
delete_databases() {
    print_section "删除数据库"
    
    # 等待 PostgreSQL 就绪
    if ! wait_for_postgresql; then
        print_warning "PostgreSQL 未就绪，无法删除数据库"
        return 1
    fi
    
    # 定义需要删除的数据库列表
    local databases=("iot-ai20" "iot-device20" "iot-video20" "ruoyi-vue-pro20")
    local deleted_count=0
    local total_count=${#databases[@]}
    
    for db_name in "${databases[@]}"; do
        if docker exec postgres-server psql -U postgres -lqt | cut -d \| -f 1 | grep -qw "$db_name"; then
            print_info "正在删除数据库: $db_name"
            if docker exec postgres-server psql -U postgres -c "DROP DATABASE \"$db_name\";" > /dev/null 2>&1; then
                print_success "数据库 $db_name 删除成功"
                deleted_count=$((deleted_count + 1))
            else
                print_error "数据库 $db_name 删除失败"
            fi
        else
            print_info "数据库 $db_name 不存在，跳过删除"
            deleted_count=$((deleted_count + 1))
        fi
    done
    
    echo ""
    print_section "数据库删除结果"
    echo "成功: ${GREEN}$deleted_count${NC} / $total_count"
    
    if [ $deleted_count -eq $total_count ]; then
        print_success "所有数据库删除完成！"
        return 0
    else
        print_warning "部分数据库删除失败"
        return 1
    fi
}


# 清理所有中间件
clean_middleware() {
    print_warning "这将删除所有中间件容器、数据卷和存储目录，确定要继续吗？(y/N)"
    print_info "注意：镜像不会被删除，以节省重新下载的时间"
    print_warning "警告：这将彻底删除所有数据，包括数据库、配置和日志！"
    read -r response
    
    if [[ "$response" =~ ^([yY][eE][sS]|[yY])$ ]]; then
        print_section "清理所有中间件"
        
        check_docker "$@"
        check_docker_compose
        check_compose_file
        
        # 第一步：先停止所有容器（正常停止）
        print_info "正在停止所有中间件服务..."
        $COMPOSE_CMD -f "$COMPOSE_FILE" stop 2>&1 | tee -a "$LOG_FILE"
        
        # 等待容器停止
        sleep 3
        
        # 第二步：强制停止所有容器（处理重启循环中的容器）
        print_info "强制停止所有容器..."
        $COMPOSE_CMD -f "$COMPOSE_FILE" kill 2>&1 | tee -a "$LOG_FILE"
        
        # 等待容器完全停止
        sleep 2
        
        # 第三步：删除容器和 Docker 具名卷（明确不删除镜像）
        # 注意：使用 down -v 只会删除容器和卷，不会删除镜像
        # 如果要删除镜像，需要使用 down --rmi all 或 down --rmi local，这里不使用
        print_info "删除所有容器和 Docker 具名卷（镜像将保留，不会删除）..."
        $COMPOSE_CMD -f "$COMPOSE_FILE" down -v 2>&1 | tee -a "$LOG_FILE"
        
        # 第四步：检查并强制删除可能残留的容器（处理重启循环中的容器）
        print_info "检查并清理残留容器..."
        local remaining_containers=$($COMPOSE_CMD -f "$COMPOSE_FILE" ps -q 2>/dev/null || echo "")
        if [ -n "$remaining_containers" ]; then
            print_warning "发现残留容器，正在强制删除..."
            echo "$remaining_containers" | xargs -r docker rm -f 2>&1 | tee -a "$LOG_FILE"
        fi
        
        # 检查是否有通过 compose 项目名称创建的容器残留
        local project_containers=$(docker ps -a --filter "label=com.docker.compose.project" --format "{{.ID}}" 2>/dev/null || echo "")
        if [ -n "$project_containers" ]; then
            # 获取 compose 文件所在目录名作为项目名（如果使用默认项目名）
            local compose_dir=$(dirname "$COMPOSE_FILE")
            local project_name=$(basename "$compose_dir" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9]//g')
            # 尝试通过项目名查找容器
            local project_containers_filtered=$(docker ps -a --filter "label=com.docker.compose.project=${project_name}" --format "{{.Names}}" 2>/dev/null || echo "")
            if [ -n "$project_containers_filtered" ]; then
                print_warning "发现项目相关残留容器，正在强制删除..."
                echo "$project_containers_filtered" | xargs -r docker rm -f 2>&1 | tee -a "$LOG_FILE"
            fi
        fi
        
        # 特别处理 SRS 容器（如果存在）
        local srs_containers=$(docker ps -a --filter "name=srs" --format "{{.Names}}" 2>/dev/null || echo "")
        if [ -n "$srs_containers" ]; then
            print_warning "发现 SRS 残留容器，正在强制删除..."
            echo "$srs_containers" | xargs -r docker rm -f 2>&1 | tee -a "$LOG_FILE"
        fi
        
        # 第五步：删除所有 bind mount 的宿主机存储目录
        print_info "删除所有 bind mount 存储目录..."
        
        # 定义所有需要删除的存储目录（相对于脚本目录）
        local data_dirs=(
            "standalone-logs"           # Nacos 日志
            "db_data"                   # PostgreSQL 数据和日志
            "taos_data"                 # TDengine 数据和日志
            "redis_data"                # Redis 数据和日志
            "mq_data"                   # Kafka 数据
            "minio_data"                 # MinIO 数据和配置
            "srs_data"                  # SRS 配置、数据和回放
            "nodered_data"              # NodeRED 数据
        )
        
        # 删除每个存储目录
        local deleted_count=0
        local total_count=${#data_dirs[@]}
        
        for dir_name in "${data_dirs[@]}"; do
            local full_path="${SCRIPT_DIR}/${dir_name}"
            if [ -d "$full_path" ]; then
                print_info "删除存储目录: $full_path"
                # 先尝试直接删除（不需要root权限）
                if rm -rf "$full_path" 2>/dev/null; then
                    print_success "已删除: $dir_name"
                    deleted_count=$((deleted_count + 1))
                else
                    # 如果直接删除失败，尝试使用 sudo（如果可用）
                    if command -v sudo &> /dev/null; then
                        print_info "尝试使用 sudo 删除: $dir_name"
                        if sudo rm -rf "$full_path" 2>/dev/null; then
                            print_success "已删除（使用 sudo）: $dir_name"
                            deleted_count=$((deleted_count + 1))
                        else
                            print_warning "无法删除: $dir_name（可能需要手动删除）"
                            print_info "手动删除命令: sudo rm -rf $full_path"
                        fi
                    else
                        print_warning "无法删除: $dir_name（可能需要 root 权限）"
                        print_info "请手动删除: rm -rf $full_path 或使用 root 权限删除"
                    fi
                fi
            else
                print_info "目录不存在，跳过: $dir_name"
                deleted_count=$((deleted_count + 1))
            fi
        done
        
        # 第六步：删除 Docker 具名卷（如果还有残留）
        print_info "检查并删除残留的 Docker 具名卷..."
        local named_volumes=(
            "emqx_data"
            "emqx_log"
        )
        
        for volume_name in "${named_volumes[@]}"; do
            if docker volume inspect "$volume_name" &> /dev/null; then
                print_info "删除 Docker 具名卷: $volume_name"
                if docker volume rm "$volume_name" 2>/dev/null; then
                    print_success "已删除 Docker 卷: $volume_name"
                else
                    print_warning "删除 Docker 卷失败: $volume_name（可能仍在使用中）"
                fi
            else
                print_info "Docker 卷不存在，跳过: $volume_name"
            fi
        done
        
        echo ""
        print_section "清理结果"
        print_info "存储目录清理: ${GREEN}$deleted_count${NC} / $total_count"
        
        if [ $deleted_count -eq $total_count ]; then
            print_success "所有存储目录已彻底删除"
        else
            print_warning "部分存储目录删除失败，请手动检查"
        fi
        
        echo ""
        print_success "清理完成"
        print_info "注意：所有 Docker 镜像已保留，不会被删除"
        print_info "如需删除镜像，请手动执行: docker image prune -a"
    else
        print_info "已取消清理操作"
    fi
}

# 更新所有中间件
update_middleware() {
    print_section "更新所有中间件"
    
    check_docker "$@"
    check_docker_compose
    check_compose_file
    create_network
    
    # 创建所有中间件的存储目录（如果不存在则创建新的）
    create_all_storage_directories
    
    # 确保关键目录的权限正确
    create_postgresql_directories
    create_redis_directories
    create_nodered_directories
    create_kafka_directories
    
    prepare_srs_config
    prepare_emqx_volumes
    
    # 检查并拉取缺失的镜像（如果镜像已存在则跳过拉取）
    echo ""
    check_and_pull_images
    
    print_info "重启所有中间件服务..."
    $COMPOSE_CMD -f "$COMPOSE_FILE" up -d 2>&1 | tee -a "$LOG_FILE"
    
    print_success "所有中间件更新完成"
    echo ""
    print_info "等待服务就绪..."
    sleep 10
}

# 显示帮助信息
show_help() {
    echo "EasyAIoT 中间件部署脚本"
    echo ""
    echo "使用方法:"
    echo "  ./install.sh [命令] [服务]"
    echo ""
    echo "可用命令:"
    echo "  install         - 安装并启动所有中间件（首次运行）"
    echo "  start           - 启动所有中间件"
    echo "  stop            - 停止所有中间件"
    echo "  restart         - 重启所有中间件"
    echo "  status          - 查看所有中间件状态"
    echo "  logs            - 查看所有中间件日志"
    echo "  logs [服务]     - 查看指定服务日志"
    echo "  build           - 重新构建所有镜像"
    echo "  clean           - 清理所有容器和镜像"
    echo "  update          - 更新并重启所有中间件"
    echo "  fix-postgresql  - 修复 PostgreSQL 密码问题"
    echo "  help            - 显示此帮助信息"
    echo ""
    echo "中间件服务列表:"
    for service in "${MIDDLEWARE_SERVICES[@]}"; do
        echo "  - $service"
    done
    echo ""
}

# 主函数
main() {
    # 在执行任何命令之前（除了 help），先检查 Git
    if [ "${1:-help}" != "help" ] && [ "${1:-help}" != "--help" ] && [ "${1:-help}" != "-h" ]; then
        check_and_require_git
    fi
    
    case "${1:-help}" in
        install)
            install_middleware
            ;;
        start)
            start_middleware
            ;;
        stop)
            stop_middleware
            ;;
        restart)
            restart_middleware
            ;;
        status)
            status_middleware
            ;;
        logs)
            view_logs "$2"
            ;;
        build)
            build_middleware
            ;;
        clean)
            clean_middleware
            ;;
        update)
            update_middleware
            ;;
        fix-postgresql)
            ensure_postgresql_password
            configure_postgresql_pg_hba
            configure_postgresql_max_connections
            ;;
        help|--help|-h)
            show_help
            ;;
        *)
            print_error "未知命令: $1"
            echo ""
            show_help
            exit 1
            ;;
    esac
}

# 运行主函数
main "$@"

# 脚本结束时记录日志文件路径
if [ -n "$LOG_FILE" ] && [ -f "$LOG_FILE" ]; then
    echo "" >> "$LOG_FILE"
    echo "=========================================" >> "$LOG_FILE"
    echo "脚本结束时间: $(date '+%Y-%m-%d %H:%M:%S')" >> "$LOG_FILE"
    echo "=========================================" >> "$LOG_FILE"
    echo ""
    print_info "日志文件已保存到: $LOG_FILE"
fi
